{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqWWqw2WsvXJ",
    "outputId": "7852ea5f-c8a2-4505-b5e0-4b1447a256c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepeval in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (4.67.0)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (8.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.13.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (13.9.4)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (4.25.5)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (2.9.2)\n",
      "Requirement already satisfied: sentry-sdk in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (2.18.0)\n",
      "Requirement already satisfied: pytest-repeat in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: pytest-xdist in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: portalocker in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (2.10.1)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.3.7)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.3.15)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.2.6)\n",
      "Requirement already satisfied: ragas in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.2.4)\n",
      "Requirement already satisfied: docx2txt~=0.8 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (7.0.0)\n",
      "Requirement already satisfied: tenacity~=8.4.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (8.4.2)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc~=1.24.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (1.24.0)\n",
      "Requirement already satisfied: grpcio~=1.63.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deepeval) (1.63.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from opentelemetry-api~=1.24.0->deepeval) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (0.45b0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain->deepeval) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain->deepeval) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain->deepeval) (3.10.10)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain->deepeval) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain->deepeval) (0.1.142)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain->deepeval) (1.23.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-core->deepeval) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pydantic->deepeval) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from requests->deepeval) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from requests->deepeval) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from requests->deepeval) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from requests->deepeval) (2024.8.30)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-openai->deepeval) (1.54.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-openai->deepeval) (0.8.0)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pytest->deepeval) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pytest->deepeval) (1.5.0)\n",
      "Requirement already satisfied: execnet>=2.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from ragas->deepeval) (3.1.0)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from ragas->deepeval) (0.3.5)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from ragas->deepeval) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from ragas->deepeval) (1.4.4)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from ragas->deepeval) (0.3.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from rich->deepeval) (2.15.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from typer->deepeval) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from typer->deepeval) (1.5.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.3.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas->deepeval) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from datasets->ragas->deepeval) (0.26.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-community->ragas->deepeval) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-community->ragas->deepeval) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from langchain-community->ragas->deepeval) (2.6.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval) (1.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pandas->datasets->ragas->deepeval) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets->ragas->deepeval) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sZgEUSPwXKf",
    "outputId": "65c179ab-ea4b-4c94-f432-1f9858beb46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lm-format-enforcer in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (0.10.9)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from lm-format-enforcer) (0.3.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from lm-format-enforcer) (24.1)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from lm-format-enforcer) (2.9.2)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from lm-format-enforcer) (6.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from pydantic>=1.10.8->lm-format-enforcer) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lm-format-enforcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonschema in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (4.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from jsonschema) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from jsonschema) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from jsonschema) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from jsonschema) (0.10.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eUy1yPEww7X",
    "outputId": "870f8e2f-8bbf-488a-a335-0fb9fbb8c8c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from bitsandbytes) (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /opt/anaconda3/envs/PyTEI/lib/python3.11/site-packages (from scipy->bitsandbytes) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nzvMEfFCsxTH"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM,  AutoTokenizer\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from typing import List\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "class GPT2(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n",
    "        # Same as the previous example above\n",
    "        model = self.load_model()\n",
    "        pipeline = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            use_cache=True,\n",
    "            device_map=\"auto\",\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            top_k=5,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        # Create parser required for JSON confinement using lmformatenforcer\n",
    "        parser = JsonSchemaParser(schema.schema())\n",
    "        prefix_function = build_transformers_prefix_allowed_tokens_fn(\n",
    "            pipeline.tokenizer, parser\n",
    "        )\n",
    "\n",
    "        # Output and load valid JSON\n",
    "        output_dict = pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n",
    "        output = output_dict[0][\"generated_text\"][len(prompt) :]\n",
    "        json_result = json.loads(output)\n",
    "\n",
    "        # Return valid JSON object according to the schema DeepEval supplied\n",
    "        return schema(**json_result)\n",
    "\n",
    "    async def a_generate(self, prompt: str, schema) -> BaseModel:\n",
    "        return self.generate(prompt, schema)\n",
    "\n",
    "    # This is optional.\n",
    "    def batch_generate(self, promtps: List[str]) -> List[str]:\n",
    "        model = self.load_model()\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer(promtps, return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"GPT2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\") # Can be replaced with any huggingface model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "gpt2 = GPT2(model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5926d8d7e14045a5a0c38c4abe35d637",
      "def886ce78d14bc496e4ad4100676452",
      "533b8f75b8744aa7829e95513232c07f",
      "11219de3d43a41fdba0c1ec9ba49c253",
      "96703517d8524e54b4ee255010330223",
      "3f9b436edf1d4ed19e16f96a8010751b",
      "19507c0e638a416d98dcc1a069ed6a19",
      "557a8fe9a4a4462d9d95a3d8edb455c0",
      "94fe8bcaa42740b68715a29f502aa0f0",
      "a200a529d658494da3f15b28a7be6480",
      "c46145637f2d46109adf407cdd82490e",
      "821d5bb2717a49f9bb8435f6efd623d0",
      "40976745ef4545a5a1968cda481c6501",
      "e392be16a1fb46c092bec7f30d964b8f",
      "05c92aee57c948a49b155e9ac042487a",
      "112fe51d9d1245b3a45001301c6a219d",
      "899c1323f66c41daba920ff1c9e060c3",
      "c90abc75066e4b868b7b20636bec94b3",
      "9dee831125da40889b0b7a527a6fd389",
      "92cc65ac9ade4f81a64cb557293b9b5c",
      "61d8b19c77f44e8f8196786dc4ca033b",
      "c93cd5e3c58c4f3282111857e5986c6f",
      "b37ab99fd11149a48941f8595af9a4a0",
      "0e8f784336dc48018f9c14e74c562e2e",
      "e049512c717c4e2da36657fadfaa1200",
      "1893d3c2c13e43d8ad04afd0392c6c61",
      "1bfcf61914d44f10989a508111e84c8d",
      "9e6c32951431408384c0b3868124b13d",
      "21739e07b4994daba4300780d158f0fe",
      "e97cdc96831c4225a108fa47e86d410c",
      "66ea90171d5f4997aa0759a841138167",
      "01d0ec13a09540babc9b5b6acc695902",
      "1c1ee35fb9274d63a5dc1da853472e88",
      "60d858ebc8474084ae5abbd0d961e41b",
      "8f38bb1bf88f4a68913dbc7a3bc9a13a",
      "6b8c82c8b96b4d9083e494a60412d1e5",
      "a607cf3a39b54d76999d31ef3a785203",
      "d726c080876b49748296774ed1b2b95f",
      "bec55019e077431a891e198eb8fcb5f9",
      "e4ff9001595e45a5a7def368ca84b619",
      "7b07028c20eb40459b6d0dfb86ff7c30",
      "116104c120ce46f1926f0b9d0a24565e",
      "d8825e355dda403b8154e628c38da6cd",
      "d2515f44b7b04abf828115d1d2339bfc",
      "ff09a96b2d4d464c912f4a47799e959b",
      "35e27385a5814f7cb7aeda19f315ed71",
      "a7901eb98267405196a0217cc23cd4da",
      "b062766ac1274319ab5de2e992b2bb33",
      "d05f462fb2254c00951aa02ae8a08bcf",
      "ee15280798ab4182880917f9e01c1d33",
      "cb2c30ec43494641ab111d0db9806656",
      "f6dabc4c8c7046b7ac259031d45d46f5",
      "1fc21eb1f6824c9e88f08913e4d9beff",
      "5856d7fbea6d49bdb79a318e6bacef37",
      "2cc77212e7cb4e4ebd51a649dfdf2a41",
      "b651b35a498e4c25966081d6344d585c",
      "f1b794f20bb545dca02f0d20af9864bf",
      "0693d157bbb24491b376243b3a0f1c32",
      "6ddd3b90fc3d492995aa4558a8403d7f",
      "fe0c29fa8b2f46f2934992f572db47ee",
      "3a2aca75477d46ffb703a69e320e0858",
      "e5e0436f1e354fd88ac2ad28e954a8b7",
      "52e303add3354f23b19b718b960e3f6d",
      "f83a2a98eb8f4418ae407de98374810a",
      "68c780dc93804ea2a844c9975abd6173",
      "b555f809d41d46ccb253671728dec663"
     ]
    },
    "id": "Ia0QdjB7uMF5",
    "outputId": "2eeb009d-a5ad-459c-94f2-7a77b6d020ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   0%|                                                                                                                                                                               | 0/100 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   1%|█▋                                                                                                                                                                     | 1/100 [00:02<03:37,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   2%|███▎                                                                                                                                                                   | 2/100 [00:04<03:31,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   3%|█████                                                                                                                                                                  | 3/100 [00:06<03:24,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   4%|██████▋                                                                                                                                                                | 4/100 [00:08<03:31,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   5%|████████▎                                                                                                                                                              | 5/100 [00:10<03:17,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   6%|██████████                                                                                                                                                             | 6/100 [00:12<03:08,  2.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   7%|███████████▋                                                                                                                                                           | 7/100 [00:14<03:07,  2.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   8%|█████████████▎                                                                                                                                                         | 8/100 [00:16<03:02,  1.98s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   9%|███████████████                                                                                                                                                        | 9/100 [00:18<02:52,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  10%|████████████████▌                                                                                                                                                     | 10/100 [00:19<02:47,  1.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  11%|██████████████████▎                                                                                                                                                   | 11/100 [00:21<02:49,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  12%|███████████████████▉                                                                                                                                                  | 12/100 [00:23<02:50,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  13%|█████████████████████▌                                                                                                                                                | 13/100 [00:25<02:41,  1.85s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  14%|███████████████████████▏                                                                                                                                              | 14/100 [00:27<02:46,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  15%|████████████████████████▉                                                                                                                                             | 15/100 [00:29<02:46,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  16%|██████████████████████████▌                                                                                                                                           | 16/100 [00:31<02:39,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  17%|████████████████████████████▏                                                                                                                                         | 17/100 [00:32<02:26,  1.76s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  18%|█████████████████████████████▉                                                                                                                                        | 18/100 [00:34<02:29,  1.82s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  19%|███████████████████████████████▌                                                                                                                                      | 19/100 [00:36<02:25,  1.79s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  20%|█████████████████████████████████▏                                                                                                                                    | 20/100 [00:38<02:22,  1.79s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  21%|██████████████████████████████████▊                                                                                                                                   | 21/100 [00:40<02:30,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  22%|████████████████████████████████████▌                                                                                                                                 | 22/100 [00:42<02:28,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  23%|██████████████████████████████████████▏                                                                                                                               | 23/100 [00:44<02:22,  1.85s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  24%|███████████████████████████████████████▊                                                                                                                              | 24/100 [00:46<02:32,  2.01s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  25%|█████████████████████████████████████████▌                                                                                                                            | 25/100 [00:48<02:26,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  26%|███████████████████████████████████████████▏                                                                                                                          | 26/100 [00:50<02:20,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  27%|████████████████████████████████████████████▊                                                                                                                         | 27/100 [00:51<02:17,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  28%|██████████████████████████████████████████████▍                                                                                                                       | 28/100 [00:54<02:24,  2.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  29%|████████████████████████████████████████████████▏                                                                                                                     | 29/100 [00:56<02:27,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  30%|█████████████████████████████████████████████████▊                                                                                                                    | 30/100 [00:58<02:17,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  31%|███████████████████████████████████████████████████▍                                                                                                                  | 31/100 [01:00<02:18,  2.01s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  32%|█████████████████████████████████████████████████████                                                                                                                 | 32/100 [01:02<02:12,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  33%|██████████████████████████████████████████████████████▊                                                                                                               | 33/100 [01:03<02:03,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  34%|████████████████████████████████████████████████████████▍                                                                                                             | 34/100 [01:05<02:06,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  35%|██████████████████████████████████████████████████████████                                                                                                            | 35/100 [01:07<02:03,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  36%|███████████████████████████████████████████████████████████▊                                                                                                          | 36/100 [01:09<01:58,  1.85s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  37%|█████████████████████████████████████████████████████████████▍                                                                                                        | 37/100 [01:11<01:51,  1.77s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  38%|███████████████████████████████████████████████████████████████                                                                                                       | 38/100 [01:12<01:53,  1.83s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  39%|████████████████████████████████████████████████████████████████▋                                                                                                     | 39/100 [01:15<01:55,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  40%|██████████████████████████████████████████████████████████████████▍                                                                                                   | 40/100 [01:16<01:49,  1.83s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  41%|████████████████████████████████████████████████████████████████████                                                                                                  | 41/100 [01:18<01:54,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  42%|█████████████████████████████████████████████████████████████████████▋                                                                                                | 42/100 [01:20<01:48,  1.87s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  43%|███████████████████████████████████████████████████████████████████████▍                                                                                              | 43/100 [01:22<01:42,  1.80s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  44%|█████████████████████████████████████████████████████████████████████████                                                                                             | 44/100 [01:24<01:47,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  45%|██████████████████████████████████████████████████████████████████████████▋                                                                                           | 45/100 [01:26<01:45,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  46%|████████████████████████████████████████████████████████████████████████████▎                                                                                         | 46/100 [01:28<01:45,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  47%|██████████████████████████████████████████████████████████████████████████████                                                                                        | 47/100 [01:30<01:39,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  48%|███████████████████████████████████████████████████████████████████████████████▋                                                                                      | 48/100 [01:32<01:40,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  49%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 49/100 [01:34<01:38,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  50%|███████████████████████████████████████████████████████████████████████████████████                                                                                   | 50/100 [01:35<01:31,  1.83s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  51%|████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 51/100 [01:37<01:32,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  52%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                               | 52/100 [01:39<01:30,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  53%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 53/100 [01:41<01:25,  1.82s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  54%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                            | 54/100 [01:43<01:23,  1.81s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  55%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 55/100 [01:45<01:24,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  56%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 56/100 [01:47<01:23,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  57%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                                       | 57/100 [01:48<01:18,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  58%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 58/100 [01:50<01:19,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 59/100 [01:52<01:20,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 60/100 [01:54<01:16,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 61/100 [01:56<01:16,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 62/100 [01:58<01:14,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  63%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 63/100 [02:01<01:22,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 64/100 [02:03<01:21,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 65/100 [02:07<01:29,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 66/100 [02:09<01:25,  2.51s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                      | 67/100 [02:11<01:15,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 68/100 [02:13<01:12,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 69/100 [02:15<01:10,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 70/100 [02:17<01:04,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 71/100 [02:21<01:13,  2.53s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 72/100 [02:23<01:06,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 73/100 [02:24<00:58,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 74/100 [02:26<00:55,  2.14s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 75/100 [02:29<00:57,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                       | 76/100 [02:31<00:56,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 77/100 [02:35<00:59,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 78/100 [02:37<00:55,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 79/100 [02:39<00:49,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 80/100 [02:41<00:42,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 81/100 [02:43<00:40,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 82/100 [02:45<00:36,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 83/100 [02:46<00:33,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 84/100 [02:48<00:31,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 85/100 [02:50<00:28,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 86/100 [02:52<00:26,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 87/100 [02:54<00:23,  1.82s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 88/100 [02:56<00:23,  2.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 89/100 [02:58<00:21,  1.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 90/100 [03:00<00:18,  1.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 91/100 [03:02<00:17,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 92/100 [03:04<00:16,  2.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 93/100 [03:05<00:13,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 94/100 [03:08<00:11,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 95/100 [03:09<00:09,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎      | 96/100 [03:11<00:07,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 97/100 [03:13<00:05,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 98/100 [03:15<00:04,  2.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 99/100 [03:18<00:02,  2.04s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:21<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=high_school_computer_science): 0.22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfd084ff65a4b0f8025432d7214f754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ea7a2b6b564684848e375745f0a62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c45b85404cb4b5cbedba4002702d3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing astronomy:   0%|                                                                                                                                                                                                  | 0/152 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   1%|█▏                                                                                                                                                                                        | 1/152 [00:02<05:40,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   1%|██▍                                                                                                                                                                                       | 2/152 [00:04<05:20,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   2%|███▋                                                                                                                                                                                      | 3/152 [00:06<05:26,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   3%|████▉                                                                                                                                                                                     | 4/152 [00:08<04:53,  1.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   3%|██████                                                                                                                                                                                    | 5/152 [00:10<05:22,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   4%|███████▎                                                                                                                                                                                  | 6/152 [00:13<05:28,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   5%|████████▌                                                                                                                                                                                 | 7/152 [00:15<05:07,  2.12s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   5%|█████████▊                                                                                                                                                                                | 8/152 [00:17<05:11,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   6%|███████████                                                                                                                                                                               | 9/152 [00:19<04:58,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   7%|████████████▏                                                                                                                                                                            | 10/152 [00:21<04:47,  2.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   7%|█████████████▍                                                                                                                                                                           | 11/152 [00:22<04:41,  2.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   8%|██████████████▌                                                                                                                                                                          | 12/152 [00:24<04:31,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   9%|███████████████▊                                                                                                                                                                         | 13/152 [00:26<04:24,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   9%|█████████████████                                                                                                                                                                        | 14/152 [00:28<04:15,  1.85s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  10%|██████████████████▎                                                                                                                                                                      | 15/152 [00:30<04:15,  1.87s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  11%|███████████████████▍                                                                                                                                                                     | 16/152 [00:32<04:10,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  11%|████████████████████▋                                                                                                                                                                    | 17/152 [00:33<04:02,  1.80s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  12%|█████████████████████▉                                                                                                                                                                   | 18/152 [00:36<04:20,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  12%|███████████████████████▏                                                                                                                                                                 | 19/152 [00:38<04:33,  2.06s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  13%|████████████████████████▎                                                                                                                                                                | 20/152 [00:40<04:15,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  14%|█████████████████████████▌                                                                                                                                                               | 21/152 [00:42<04:27,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  14%|██████████████████████████▊                                                                                                                                                              | 22/152 [00:44<04:26,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  15%|███████████████████████████▉                                                                                                                                                             | 23/152 [00:46<04:18,  2.01s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  16%|█████████████████████████████▏                                                                                                                                                           | 24/152 [00:47<04:06,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  16%|██████████████████████████████▍                                                                                                                                                          | 25/152 [00:50<04:10,  1.98s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  17%|███████████████████████████████▋                                                                                                                                                         | 26/152 [00:51<04:03,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  18%|████████████████████████████████▊                                                                                                                                                        | 27/152 [00:53<03:54,  1.87s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  18%|██████████████████████████████████                                                                                                                                                       | 28/152 [00:56<04:10,  2.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  19%|███████████████████████████████████▎                                                                                                                                                     | 29/152 [00:57<03:59,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  20%|████████████████████████████████████▌                                                                                                                                                    | 30/152 [00:59<03:51,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  20%|█████████████████████████████████████▋                                                                                                                                                   | 31/152 [01:01<04:01,  2.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  21%|██████████████████████████████████████▉                                                                                                                                                  | 32/152 [01:03<03:56,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  22%|████████████████████████████████████████▏                                                                                                                                                | 33/152 [01:05<03:50,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  22%|█████████████████████████████████████████▍                                                                                                                                               | 34/152 [01:07<03:41,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  23%|██████████████████████████████████████████▌                                                                                                                                              | 35/152 [01:09<03:39,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  24%|███████████████████████████████████████████▊                                                                                                                                             | 36/152 [01:10<03:35,  1.85s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  24%|█████████████████████████████████████████████                                                                                                                                            | 37/152 [01:12<03:23,  1.77s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  25%|██████████████████████████████████████████████▎                                                                                                                                          | 38/152 [01:14<03:34,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  26%|███████████████████████████████████████████████▍                                                                                                                                         | 39/152 [01:16<03:41,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  26%|████████████████████████████████████████████████▋                                                                                                                                        | 40/152 [01:18<03:33,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  27%|█████████████████████████████████████████████████▉                                                                                                                                       | 41/152 [01:20<03:35,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  28%|███████████████████████████████████████████████████                                                                                                                                      | 42/152 [01:22<03:38,  1.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  28%|████████████████████████████████████████████████████▎                                                                                                                                    | 43/152 [01:24<03:29,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  29%|█████████████████████████████████████████████████████▌                                                                                                                                   | 44/152 [01:26<03:26,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  30%|██████████████████████████████████████████████████████▊                                                                                                                                  | 45/152 [01:28<03:25,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  30%|███████████████████████████████████████████████████████▉                                                                                                                                 | 46/152 [01:30<03:18,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  31%|█████████████████████████████████████████████████████████▏                                                                                                                               | 47/152 [01:31<03:06,  1.78s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  32%|██████████████████████████████████████████████████████████▍                                                                                                                              | 48/152 [01:33<03:13,  1.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  32%|███████████████████████████████████████████████████████████▋                                                                                                                             | 49/152 [01:35<03:16,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  33%|████████████████████████████████████████████████████████████▊                                                                                                                            | 50/152 [01:37<03:05,  1.82s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  34%|██████████████████████████████████████████████████████████████                                                                                                                           | 51/152 [01:39<03:10,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  34%|███████████████████████████████████████████████████████████████▎                                                                                                                         | 52/152 [01:41<03:03,  1.83s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  35%|████████████████████████████████████████████████████████████████▌                                                                                                                        | 53/152 [01:43<03:08,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  36%|█████████████████████████████████████████████████████████████████▋                                                                                                                       | 54/152 [01:44<02:56,  1.81s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  36%|██████████████████████████████████████████████████████████████████▉                                                                                                                      | 55/152 [01:46<03:02,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  37%|████████████████████████████████████████████████████████████████████▏                                                                                                                    | 56/152 [01:48<03:00,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  38%|█████████████████████████████████████████████████████████████████████▍                                                                                                                   | 57/152 [01:50<02:54,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  38%|██████████████████████████████████████████████████████████████████████▌                                                                                                                  | 58/152 [01:52<02:58,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  39%|███████████████████████████████████████████████████████████████████████▊                                                                                                                 | 59/152 [01:54<03:00,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  39%|█████████████████████████████████████████████████████████████████████████                                                                                                                | 60/152 [01:56<02:49,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  40%|██████████████████████████████████████████████████████████████████████████▏                                                                                                              | 61/152 [01:58<02:56,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  41%|███████████████████████████████████████████████████████████████████████████▍                                                                                                             | 62/152 [02:00<02:56,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  41%|████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 63/152 [02:02<02:56,  1.98s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  42%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                           | 64/152 [02:03<02:42,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  43%|███████████████████████████████████████████████████████████████████████████████                                                                                                          | 65/152 [02:06<02:48,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  43%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                        | 66/152 [02:08<02:48,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  44%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                       | 67/152 [02:09<02:36,  1.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  45%|██████████████████████████████████████████████████████████████████████████████████▊                                                                                                      | 68/152 [02:11<02:42,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  45%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 69/152 [02:13<02:39,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  46%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                   | 70/152 [02:15<02:32,  1.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  47%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                                                  | 71/152 [02:17<02:34,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  47%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                                                 | 72/152 [02:19<02:32,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  48%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 73/152 [02:21<02:35,  1.96s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  49%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                               | 74/152 [02:23<02:29,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  49%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                                             | 75/152 [02:25<02:31,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  50%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                            | 76/152 [02:27<02:25,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  51%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                           | 77/152 [02:28<02:19,  1.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  51%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                          | 78/152 [02:30<02:21,  1.92s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  52%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                        | 79/152 [02:35<03:19,  2.73s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  53%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 80/152 [02:37<02:58,  2.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  53%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                      | 81/152 [02:39<02:57,  2.51s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  54%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                     | 82/152 [02:41<02:40,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  55%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 83/152 [02:43<02:27,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  55%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 84/152 [02:45<02:19,  2.06s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                 | 85/152 [02:47<02:17,  2.06s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  57%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                | 86/152 [02:49<02:08,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                               | 87/152 [02:52<02:33,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 88/152 [02:55<02:40,  2.51s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 89/152 [02:57<02:28,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 90/152 [02:59<02:15,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                          | 91/152 [03:01<02:17,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  61%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 92/152 [03:03<02:10,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                       | 93/152 [03:06<02:15,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                      | 94/152 [03:07<02:00,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 95/152 [03:09<02:00,  2.12s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 96/152 [03:11<01:57,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 97/152 [03:13<01:53,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 98/152 [03:17<02:23,  2.66s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 99/152 [03:20<02:15,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 100/152 [03:21<01:55,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 101/152 [03:24<01:55,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 102/152 [03:26<01:49,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                           | 103/152 [03:28<01:45,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 104/152 [03:30<01:47,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 105/152 [03:32<01:46,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 106/152 [03:35<01:43,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 107/152 [03:36<01:34,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 108/152 [03:38<01:32,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 109/152 [03:40<01:30,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 110/152 [03:42<01:23,  2.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 111/152 [03:44<01:22,  2.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 112/152 [03:46<01:19,  1.98s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 113/152 [03:49<01:22,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 114/152 [03:51<01:20,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 115/152 [03:53<01:21,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 116/152 [03:55<01:14,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 117/152 [03:57<01:07,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 118/152 [03:59<01:10,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 119/152 [04:01<01:07,  2.04s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 120/152 [04:03<01:02,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 121/152 [04:05<01:02,  2.01s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 122/152 [04:07<00:58,  1.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 123/152 [04:09<00:57,  1.97s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 124/152 [04:10<00:53,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 125/152 [04:13<00:54,  2.04s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 126/152 [04:15<00:53,  2.06s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 127/152 [04:17<00:51,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 128/152 [04:19<00:50,  2.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 129/152 [04:21<00:47,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 130/152 [04:23<00:45,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 131/152 [04:25<00:43,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 132/152 [04:27<00:40,  2.04s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 133/152 [04:29<00:39,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 134/152 [04:31<00:35,  1.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 135/152 [04:33<00:35,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 136/152 [04:35<00:32,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 137/152 [04:37<00:28,  1.90s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 138/152 [04:39<00:27,  1.95s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 139/152 [04:41<00:25,  1.98s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 140/152 [04:43<00:22,  1.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 141/152 [04:45<00:20,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 142/152 [04:46<00:18,  1.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 143/152 [04:49<00:17,  1.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 144/152 [04:50<00:15,  1.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 145/152 [04:53<00:13,  1.98s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 146/152 [04:54<00:11,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 147/152 [04:56<00:08,  1.78s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 148/152 [04:58<00:07,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 149/152 [05:00<00:05,  1.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 150/152 [05:02<00:03,  1.82s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 151/152 [05:04<00:01,  1.88s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 152/152 [05:06<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=astronomy): 0.21710526315789475\n",
      "Overall MMLU Accuracy: 0.21825396825396826\n",
      "0.21825396825396826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from deepeval.benchmarks import MMLU\n",
    "from deepeval.benchmarks.tasks import MMLUTask\n",
    "\n",
    "# Benchmarks include MMLU, HellaSwag, BigBench, TruthfulQA, DROP, HumanEval, GSM8K\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "benchmark = MMLU(\n",
    "    tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE, MMLUTask.ASTRONOMY],\n",
    "    n_shots=3\n",
    ")\n",
    "\n",
    "# Replace 'gpt2' with testing model\n",
    "benchmark.evaluate(model=gpt2)\n",
    "print(benchmark.overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Task     Score\n",
      "0  high_school_computer_science  0.220000\n",
      "1                     astronomy  0.217105\n"
     ]
    }
   ],
   "source": [
    "print(benchmark.task_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTAWpo7M6sww"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "def convert_torch_to_huggingface(model: torch.nn.Module):\n",
    "  config = AutoConfig.from_pretrained(\"gpt2\") # Change to whichever model architecture being used\n",
    "  hf_model = AutoModelForCausalLM.from_config(config)\n",
    "  hf_model.load_state_dict(model.state_dict())\n",
    "  return hf_model\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01d0ec13a09540babc9b5b6acc695902": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05c92aee57c948a49b155e9ac042487a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61d8b19c77f44e8f8196786dc4ca033b",
      "placeholder": "​",
      "style": "IPY_MODEL_c93cd5e3c58c4f3282111857e5986c6f",
      "value": " 9/9 [00:00&lt;00:00, 237.20 examples/s]"
     }
    },
    "0693d157bbb24491b376243b3a0f1c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52e303add3354f23b19b718b960e3f6d",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f83a2a98eb8f4418ae407de98374810a",
      "value": 5
     }
    },
    "0e8f784336dc48018f9c14e74c562e2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e6c32951431408384c0b3868124b13d",
      "placeholder": "​",
      "style": "IPY_MODEL_21739e07b4994daba4300780d158f0fe",
      "value": "Generating train split: 100%"
     }
    },
    "11219de3d43a41fdba0c1ec9ba49c253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a200a529d658494da3f15b28a7be6480",
      "placeholder": "​",
      "style": "IPY_MODEL_c46145637f2d46109adf407cdd82490e",
      "value": " 100/100 [00:00&lt;00:00, 1345.74 examples/s]"
     }
    },
    "112fe51d9d1245b3a45001301c6a219d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "116104c120ce46f1926f0b9d0a24565e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1893d3c2c13e43d8ad04afd0392c6c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01d0ec13a09540babc9b5b6acc695902",
      "placeholder": "​",
      "style": "IPY_MODEL_1c1ee35fb9274d63a5dc1da853472e88",
      "value": " 5/5 [00:00&lt;00:00, 75.21 examples/s]"
     }
    },
    "19507c0e638a416d98dcc1a069ed6a19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bfcf61914d44f10989a508111e84c8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c1ee35fb9274d63a5dc1da853472e88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc21eb1f6824c9e88f08913e4d9beff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "21739e07b4994daba4300780d158f0fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cc77212e7cb4e4ebd51a649dfdf2a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35e27385a5814f7cb7aeda19f315ed71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee15280798ab4182880917f9e01c1d33",
      "placeholder": "​",
      "style": "IPY_MODEL_cb2c30ec43494641ab111d0db9806656",
      "value": "Generating validation split: 100%"
     }
    },
    "3a2aca75477d46ffb703a69e320e0858": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9b436edf1d4ed19e16f96a8010751b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40976745ef4545a5a1968cda481c6501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_899c1323f66c41daba920ff1c9e060c3",
      "placeholder": "​",
      "style": "IPY_MODEL_c90abc75066e4b868b7b20636bec94b3",
      "value": "Generating validation split: 100%"
     }
    },
    "52e303add3354f23b19b718b960e3f6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "533b8f75b8744aa7829e95513232c07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_557a8fe9a4a4462d9d95a3d8edb455c0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94fe8bcaa42740b68715a29f502aa0f0",
      "value": 100
     }
    },
    "557a8fe9a4a4462d9d95a3d8edb455c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5856d7fbea6d49bdb79a318e6bacef37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5926d8d7e14045a5a0c38c4abe35d637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_def886ce78d14bc496e4ad4100676452",
       "IPY_MODEL_533b8f75b8744aa7829e95513232c07f",
       "IPY_MODEL_11219de3d43a41fdba0c1ec9ba49c253"
      ],
      "layout": "IPY_MODEL_96703517d8524e54b4ee255010330223"
     }
    },
    "60d858ebc8474084ae5abbd0d961e41b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f38bb1bf88f4a68913dbc7a3bc9a13a",
       "IPY_MODEL_6b8c82c8b96b4d9083e494a60412d1e5",
       "IPY_MODEL_a607cf3a39b54d76999d31ef3a785203"
      ],
      "layout": "IPY_MODEL_d726c080876b49748296774ed1b2b95f"
     }
    },
    "61d8b19c77f44e8f8196786dc4ca033b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66ea90171d5f4997aa0759a841138167": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68c780dc93804ea2a844c9975abd6173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b8c82c8b96b4d9083e494a60412d1e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b07028c20eb40459b6d0dfb86ff7c30",
      "max": 152,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_116104c120ce46f1926f0b9d0a24565e",
      "value": 152
     }
    },
    "6ddd3b90fc3d492995aa4558a8403d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68c780dc93804ea2a844c9975abd6173",
      "placeholder": "​",
      "style": "IPY_MODEL_b555f809d41d46ccb253671728dec663",
      "value": " 5/5 [00:00&lt;00:00, 187.23 examples/s]"
     }
    },
    "7b07028c20eb40459b6d0dfb86ff7c30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "821d5bb2717a49f9bb8435f6efd623d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40976745ef4545a5a1968cda481c6501",
       "IPY_MODEL_e392be16a1fb46c092bec7f30d964b8f",
       "IPY_MODEL_05c92aee57c948a49b155e9ac042487a"
      ],
      "layout": "IPY_MODEL_112fe51d9d1245b3a45001301c6a219d"
     }
    },
    "899c1323f66c41daba920ff1c9e060c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f38bb1bf88f4a68913dbc7a3bc9a13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bec55019e077431a891e198eb8fcb5f9",
      "placeholder": "​",
      "style": "IPY_MODEL_e4ff9001595e45a5a7def368ca84b619",
      "value": "Generating test split: 100%"
     }
    },
    "92cc65ac9ade4f81a64cb557293b9b5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94fe8bcaa42740b68715a29f502aa0f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96703517d8524e54b4ee255010330223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dee831125da40889b0b7a527a6fd389": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e6c32951431408384c0b3868124b13d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a200a529d658494da3f15b28a7be6480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a607cf3a39b54d76999d31ef3a785203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8825e355dda403b8154e628c38da6cd",
      "placeholder": "​",
      "style": "IPY_MODEL_d2515f44b7b04abf828115d1d2339bfc",
      "value": " 152/152 [00:00&lt;00:00, 2901.55 examples/s]"
     }
    },
    "a7901eb98267405196a0217cc23cd4da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6dabc4c8c7046b7ac259031d45d46f5",
      "max": 16,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fc21eb1f6824c9e88f08913e4d9beff",
      "value": 16
     }
    },
    "b062766ac1274319ab5de2e992b2bb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5856d7fbea6d49bdb79a318e6bacef37",
      "placeholder": "​",
      "style": "IPY_MODEL_2cc77212e7cb4e4ebd51a649dfdf2a41",
      "value": " 16/16 [00:00&lt;00:00, 605.99 examples/s]"
     }
    },
    "b37ab99fd11149a48941f8595af9a4a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e8f784336dc48018f9c14e74c562e2e",
       "IPY_MODEL_e049512c717c4e2da36657fadfaa1200",
       "IPY_MODEL_1893d3c2c13e43d8ad04afd0392c6c61"
      ],
      "layout": "IPY_MODEL_1bfcf61914d44f10989a508111e84c8d"
     }
    },
    "b555f809d41d46ccb253671728dec663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b651b35a498e4c25966081d6344d585c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1b794f20bb545dca02f0d20af9864bf",
       "IPY_MODEL_0693d157bbb24491b376243b3a0f1c32",
       "IPY_MODEL_6ddd3b90fc3d492995aa4558a8403d7f"
      ],
      "layout": "IPY_MODEL_fe0c29fa8b2f46f2934992f572db47ee"
     }
    },
    "bec55019e077431a891e198eb8fcb5f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c46145637f2d46109adf407cdd82490e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c90abc75066e4b868b7b20636bec94b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c93cd5e3c58c4f3282111857e5986c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb2c30ec43494641ab111d0db9806656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d05f462fb2254c00951aa02ae8a08bcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2515f44b7b04abf828115d1d2339bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d726c080876b49748296774ed1b2b95f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8825e355dda403b8154e628c38da6cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "def886ce78d14bc496e4ad4100676452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f9b436edf1d4ed19e16f96a8010751b",
      "placeholder": "​",
      "style": "IPY_MODEL_19507c0e638a416d98dcc1a069ed6a19",
      "value": "Generating test split: 100%"
     }
    },
    "e049512c717c4e2da36657fadfaa1200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e97cdc96831c4225a108fa47e86d410c",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66ea90171d5f4997aa0759a841138167",
      "value": 5
     }
    },
    "e392be16a1fb46c092bec7f30d964b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dee831125da40889b0b7a527a6fd389",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92cc65ac9ade4f81a64cb557293b9b5c",
      "value": 9
     }
    },
    "e4ff9001595e45a5a7def368ca84b619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5e0436f1e354fd88ac2ad28e954a8b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e97cdc96831c4225a108fa47e86d410c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee15280798ab4182880917f9e01c1d33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b794f20bb545dca02f0d20af9864bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a2aca75477d46ffb703a69e320e0858",
      "placeholder": "​",
      "style": "IPY_MODEL_e5e0436f1e354fd88ac2ad28e954a8b7",
      "value": "Generating train split: 100%"
     }
    },
    "f6dabc4c8c7046b7ac259031d45d46f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f83a2a98eb8f4418ae407de98374810a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe0c29fa8b2f46f2934992f572db47ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff09a96b2d4d464c912f4a47799e959b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35e27385a5814f7cb7aeda19f315ed71",
       "IPY_MODEL_a7901eb98267405196a0217cc23cd4da",
       "IPY_MODEL_b062766ac1274319ab5de2e992b2bb33"
      ],
      "layout": "IPY_MODEL_d05f462fb2254c00951aa02ae8a08bcf"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
