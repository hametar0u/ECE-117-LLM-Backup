{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72dc17a-93e0-42ea-9e2d-95696b6ac60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# this prints out the named parameters of a model\n",
    "def print_named_params(model: nn.Module) -> None:\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.shape}\")\n",
    "\n",
    "def output_targets(model: nn.Module, file: str) -> None:\n",
    "    with open(file, 'w') as f:\n",
    "        for name, param in model.named_parameters():\n",
    "            f.write(f\"{name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d9042c-0d93-4d91-b02e-fecd5320f3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "#import timm\n",
    "torch.set_printoptions(precision = 6, sci_mode = False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36799eac-0990-4aeb-9d8b-083b2ae5e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../pytei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631b02be-e027-46ca-b1a5-98c884dc5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912fb192-a436-4a71-97bf-b5ec8e3db63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytei import Injector\n",
    "def inject_error(model: nn.Module, error_map_file: str, prob) -> nn.Module:\n",
    "    model_error = deepcopy(model).to(device)\n",
    "    injector = Injector(error_map_file, p = prob, device = device, verbose = True)\n",
    "    injector.inject(model_error)\n",
    "    return model_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd5871-9df3-490f-a87c-68ebc4821cd3",
   "metadata": {},
   "source": [
    "## GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e588c5ad-80a7-4ffd-96d4-6fcdf4ed754c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69d043-19ce-44ab-aadd-162ed60b5999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6235a7b-b8db-47fc-862f-03128de51112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import T5Tokenizer, T5Model\n",
    "from collections import OrderedDict\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "gpt2 = T5Model.from_pretrained('t5-base')\n",
    "\n",
    "def get_modified_state_dictGPT2(model: nn.Module):\n",
    "    new_state_dict = deepcopy(model.state_dict())\n",
    "    for key in list(new_state_dict.keys()):\n",
    "        new_state_dict[f\"transformer.{key}\"] = new_state_dict.pop(key)\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9124bacd-3227-45d9-96fc-12fb31c9892c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight: torch.Size([32128, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12])\n",
      "encoder.block.0.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.0.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.1.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.2.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.3.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.4.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.5.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.6.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.7.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.8.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.9.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.10.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.11.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.final_layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12])\n",
      "decoder.block.0.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.0.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.1.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.2.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.3.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.4.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.5.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.6.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.7.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.8.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.9.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.10.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.11.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.final_layer_norm.weight: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print_named_params(gpt2)\n",
    "output_targets(gpt2, \"gpt2_targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94bb3fab-681e-4ba1-afea-cf0b589e58bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "inject_error() missing 1 required positional argument: 'prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt2_error \u001b[38;5;241m=\u001b[39m inject_error(gpt2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2_targets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m gpt2_error\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblahblahblah\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: inject_error() missing 1 required positional argument: 'prob'"
     ]
    }
   ],
   "source": [
    "gpt2_error = inject_error(gpt2, \"gpt2_targets\")\n",
    "gpt2_error.eval()\n",
    "text = \"blahblahblah\"\n",
    "test_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    error_out = gpt2_error(**test_input) # gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35275cb2-b50e-41e9-997f-73bdecf03dca",
   "metadata": {},
   "source": [
    "## MAMBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa435f96-ede5-4424-b7bc-753763bcd349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8dbb43-33cb-4a97-8b63-eca53df09a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8f761ed-99ee-464b-848f-9a7b6f4bf999",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6dd06f-29ee-4135-a34a-d3837c566909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepeval\n",
      "  Downloading deepeval-1.5.9-py3-none-any.whl.metadata (977 bytes)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (4.66.5)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (7.4.4)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (0.9.0)\n",
      "Collecting typer (from deepeval)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (13.7.1)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (4.25.3)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (2.8.2)\n",
      "Collecting sentry-sdk (from deepeval)\n",
      "  Downloading sentry_sdk-2.19.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pytest-repeat (from deepeval)\n",
      "  Using cached pytest_repeat-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pytest-xdist (from deepeval)\n",
      "  Using cached pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting portalocker (from deepeval)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain (from deepeval)\n",
      "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core (from deepeval)\n",
      "  Downloading langchain_core-0.3.20-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-openai (from deepeval)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ragas (from deepeval)\n",
      "  Downloading ragas-0.2.6-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting docx2txt~=0.8 (from deepeval)\n",
      "  Using cached docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from deepeval) (7.0.1)\n",
      "Collecting tenacity~=8.4.1 (from deepeval)\n",
      "  Using cached tenacity-8.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-api~=1.24.0 (from deepeval)\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-sdk~=1.24.0 (from deepeval)\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc~=1.24.0 (from deepeval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpcio~=1.63.0 (from deepeval)\n",
      "  Downloading grpcio-1.63.2-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata>=6.0.2->deepeval) (3.17.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api~=1.24.0->deepeval)\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting importlib-metadata>=6.0.2 (from deepeval)\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc~=1.24.0->deepeval)\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk~=1.24.0->deepeval)\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-sdk~=1.24.0->deepeval) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain->deepeval) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain->deepeval) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain->deepeval) (3.10.5)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain->deepeval)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain->deepeval)\n",
      "  Downloading langsmith-0.1.144-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain->deepeval) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core->deepeval) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->deepeval) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->deepeval) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->deepeval) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->deepeval) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->deepeval) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->deepeval) (2024.8.30)\n",
      "Collecting openai<2.0.0,>=1.54.0 (from langchain-openai->deepeval)\n",
      "  Downloading openai-1.55.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai->deepeval)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.12/site-packages (from pytest->deepeval) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/anaconda3/lib/python3.12/site-packages (from pytest->deepeval) (1.0.0)\n",
      "Collecting execnet>=2.1 (from pytest-xdist->deepeval)\n",
      "  Using cached execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting datasets (from ragas->deepeval)\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting langchain-community (from ragas->deepeval)\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.12/site-packages (from ragas->deepeval) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /opt/anaconda3/lib/python3.12/site-packages (from ragas->deepeval) (1.4.4)\n",
      "Collecting pysbd>=0.3.4 (from ragas->deepeval)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->deepeval) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->deepeval) (2.15.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer->deepeval) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer->deepeval)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->deepeval) (1.11.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24.0->deepeval) (1.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain->deepeval)\n",
      "  Downloading orjson-3.10.11-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval)\n",
      "  Downloading jiter-0.7.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.54.0->langchain-openai->deepeval) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai->deepeval) (2024.9.11)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas->deepeval) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas->deepeval) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas->deepeval) (2.2.2)\n",
      "Collecting xxhash (from datasets->ragas->deepeval)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas->deepeval)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas->deepeval) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets->ragas->deepeval) (0.26.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->ragas->deepeval)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community->ragas->deepeval)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->ragas->deepeval)\n",
      "  Using cached pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval)\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas->deepeval) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets->ragas->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets->ragas->deepeval) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets->ragas->deepeval) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas->deepeval) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas->deepeval) (1.0.0)\n",
      "Downloading deepeval-1.5.9-py3-none-any.whl (467 kB)\n",
      "Downloading grpcio-1.63.2-cp312-cp312-macosx_10_9_universal2.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Using cached tenacity-8.4.2-py3-none-any.whl (28 kB)\n",
      "Using cached langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_core-0.3.20-py3-none-any.whl (409 kB)\n",
      "Downloading langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
      "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Using cached pytest_repeat-0.9.3-py3-none-any.whl (4.2 kB)\n",
      "Using cached pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n",
      "Downloading ragas-0.2.6-py3-none-any.whl (157 kB)\n",
      "Downloading sentry_sdk-2.19.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached execnet-2.1.1-py3-none-any.whl (40 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.144-py3-none-any.whl (310 kB)\n",
      "Downloading openai-1.55.0-py3-none-any.whl (389 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.6/982.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading jiter-0.7.1-cp312-cp312-macosx_11_0_arm64.whl (304 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading orjson-3.10.11-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (266 kB)\n",
      "Using cached pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=fcadfdfa1d673a00ae2e43eca5ace146da617e5632fce5c756dd69fef3e62ce1\n",
      "  Stored in directory: /Users/ausca/Library/Caches/pip/wheels/6f/81/48/001bbc0109c15e18c009eee300022f42d1e070e54f1d00b218\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt, xxhash, typing-inspect, tenacity, shellingham, sentry-sdk, pysbd, portalocker, orjson, opentelemetry-semantic-conventions, opentelemetry-proto, multiprocess, marshmallow, jiter, importlib-metadata, httpx-sse, grpcio, googleapis-common-protos, execnet, deprecated, tiktoken, pytest-xdist, pytest-repeat, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, dataclasses-json, typer, pydantic-settings, opentelemetry-sdk, openai, langsmith, opentelemetry-exporter-otlp-proto-grpc, langchain-core, datasets, langchain-text-splitters, langchain-openai, langchain, langchain-community, ragas, deepeval\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.3\n",
      "    Uninstalling tenacity-8.2.3:\n",
      "      Successfully uninstalled tenacity-8.2.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "Successfully installed dataclasses-json-0.6.7 datasets-3.1.0 deepeval-1.5.9 deprecated-1.2.15 docx2txt-0.8 execnet-2.1.1 googleapis-common-protos-1.66.0 grpcio-1.63.2 httpx-sse-0.4.0 importlib-metadata-7.0.0 jiter-0.7.1 langchain-0.3.7 langchain-community-0.3.7 langchain-core-0.3.20 langchain-openai-0.2.9 langchain-text-splitters-0.3.2 langsmith-0.1.144 marshmallow-3.23.1 multiprocess-0.70.16 openai-1.55.0 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 orjson-3.10.11 portalocker-3.0.0 pydantic-settings-2.6.1 pysbd-0.3.4 pytest-repeat-0.9.3 pytest-xdist-3.6.1 ragas-0.2.6 sentry-sdk-2.19.0 shellingham-1.5.4 tenacity-8.4.2 tiktoken-0.8.0 typer-0.13.1 typing-inspect-0.9.0 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a31df0c-e463-4ba2-9143-2f6f440cc643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5efdef05-7d24-400e-aa9b-a919c920f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/anaconda3/lib/python3.12/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /opt/anaconda3/lib/python3.12/site-packages (from scipy->bitsandbytes) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ee44e2-d079-4715-a6c0-3c134a6425a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BitsAndBytesConfig' from 'bitsandbytes' (/opt/anaconda3/lib/python3.12/site-packages/bitsandbytes/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepEvalBaseLLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BitsAndBytesConfig\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMistral7B\u001b[39;00m(DeepEvalBaseLLM):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      9\u001b[0m         model,\n\u001b[1;32m     10\u001b[0m         tokenizer\n\u001b[1;32m     11\u001b[0m     ):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BitsAndBytesConfig' from 'bitsandbytes' (/opt/anaconda3/lib/python3.12/site-packages/bitsandbytes/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from typing import List\n",
    "from bitsandbytes import BitsAndBytesConfig\n",
    "\n",
    "class Mistral7B(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        model = self.load_model()\n",
    "\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    # This is optional.\n",
    "    def batch_generate(self, promtps: List[str]) -> List[str]:\n",
    "        model = self.load_model()\n",
    "        device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "        model_inputs = self.tokenizer(promtps, return_tensors=\"pt\").to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "        return self.tokenizer.batch_decode(generated_ids)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Mistral 7B\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
    "import torch\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "token = \"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\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        token=token\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", token=\"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\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "#mistral_7b = Mistral7B(model=model, tokenizer=tokenizer)\n",
    "#print(mistral_7b(\"Write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0dd53b-2d90-47ec-a33f-7e03eef2e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", token=\"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\")\n",
    "mistral_7b = Mistral7B(model=model, tokenizer=tokenizer)\n",
    "evaluate_model_MMLU(mistral_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7f40e6-3988-4535-982d-4e8d10502f76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, ElectraConfig, ErnieConfig, FalconConfig, FalconMambaConfig, FuyuConfig, GemmaConfig, Gemma2Config, GitConfig, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, JambaConfig, JetMoeConfig, LlamaConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MllamaConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, ZambaConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mtask_scores\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m hf_model \u001b[38;5;241m=\u001b[39m T5(model, tokenizer)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:567\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[0;32m--> 567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, ElectraConfig, ErnieConfig, FalconConfig, FalconMambaConfig, FuyuConfig, GemmaConfig, Gemma2Config, GitConfig, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, JambaConfig, JetMoeConfig, LlamaConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MllamaConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, ZambaConfig."
     ]
    }
   ],
   "source": [
    "from deepeval.benchmarks import MMLU\n",
    "from deepeval.benchmarks.tasks import MMLUTask\n",
    "\n",
    "def evaluate_model_MMLU(model):\n",
    "\n",
    "    benchmark = MMLU(\n",
    "        tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE, MMLUTask.ASTRONOMY],\n",
    "        n_shots=3\n",
    "    )\n",
    "\n",
    "    benchmark.evaluate(model=model)\n",
    "    return benchmark.task_scores\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "hf_model = T5(model, tokenizer)\n",
    "evaluate_model_MMLU(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b91f5df-4ee1-461b-9cd1-7b08da2951ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight: torch.Size([32128, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12])\n",
      "encoder.block.0.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.0.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.1.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.2.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.3.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.4.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.5.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.6.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.7.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.8.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.9.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.10.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.11.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.final_layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12])\n",
      "decoder.block.0.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.0.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.1.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.2.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.3.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.4.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.5.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.6.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.7.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.8.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.9.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.10.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.11.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.final_layer_norm.weight: torch.Size([768])\n",
      "\n",
      "shared.weight: torch.Size([32128, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12])\n",
      "encoder.block.0.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.0.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.1.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.1.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.2.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.2.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.3.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.3.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.4.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.4.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.5.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.5.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.6.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.6.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.7.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.7.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.8.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.8.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.9.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.9.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.10.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.10.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "encoder.block.11.layer.0.layer_norm.weight: torch.Size([768])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "encoder.block.11.layer.1.layer_norm.weight: torch.Size([768])\n",
      "encoder.final_layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: torch.Size([32, 12])\n",
      "decoder.block.0.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.0.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.0.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.1.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.1.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.2.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.2.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.3.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.3.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.4.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.4.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.5.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.5.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.6.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.6.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.7.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.7.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.8.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.8.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.9.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.9.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.10.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.10.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.0.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight: torch.Size([768, 768])\n",
      "decoder.block.11.layer.1.layer_norm.weight: torch.Size([768])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi.weight: torch.Size([3072, 768])\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight: torch.Size([768, 3072])\n",
      "decoder.block.11.layer.2.layer_norm.weight: torch.Size([768])\n",
      "decoder.final_layer_norm.weight: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"t5-base\") # Change to whichever model architecture being used\n",
    "hf_model = AutoModelForSeq2SeqLM.from_config(config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96ceeaf6-34fe-4846-add0-ccead613e9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   0%|                                                                                                                                                                               | 0/100 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are multiple choice questions (with answers) about high school computer science.\n",
      "\n",
      "Which of the following is an example of the use of a device on the Internet of Things (IoT) ?\n",
      "A. A car alerts a driver that it is about to hit an object.\n",
      "B. A hiker uses a G P S watch to keep track of her position.\n",
      "C. A refrigerator orders milk from an online delivery service when the milk in the refrigerator is almost gone.\n",
      "D. A runner uses a watch with optical sensors to monitor his heart rate.\n",
      "Answer: C\n",
      "\n",
      "Many Web browsers allow users to open anonymous windows. During a browsing session in an anonymous window, the browser does not record a browsing history or a list of downloaded files. When the anonymous window is exited, cookies created during the session are deleted. Which of the following statements about browsing sessions in an anonymous window is true?\n",
      "A. The activities of a user browsing in an anonymous window will not be visible to people who monitor the user's network, such as the system administrator.\n",
      "B. Items placed in a Web store's shopping cart for future purchase during the anonymous browsing session will not be saved on the user's computer.\n",
      "C. A user will not be able to log in to e-mail or social media accounts during the anonymous browsing session.\n",
      "D. A user browsing in an anonymous window will be protected from viruses launched from any web sites visited or files downloaded.\n",
      "Answer: B\n",
      "\n",
      "What is the output of \"abc\"[::-1] in Python 3?\n",
      "A. Error\n",
      "B. abc\n",
      "C. cba\n",
      "D. c\n",
      "Answer: C\n",
      "\n",
      "Let x = 1. What is x << 3 in Python 3?\n",
      "A. 1\n",
      "B. 3\n",
      "C. 8\n",
      "D. 16\n",
      "Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   0%|                                                                                                                                                                               | 0/100 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeu jeuPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCRPCR graffiti graffiti graffiti graffiti graffiti graffiti graffiti graffiti produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits produits'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#test_model = inject_error(gpt2, \"gpt2_targets\", prob)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     test_model \u001b[38;5;241m=\u001b[39m hf_model\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m evaluate_model_MMLU_GPT2(test_model)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m      8\u001b[0m         task \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[19], line 36\u001b[0m, in \u001b[0;36mevaluate_model_MMLU_GPT2\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     34\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt5-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m test_model \u001b[38;5;241m=\u001b[39m GPT2(model\u001b[38;5;241m=\u001b[39mhf_model, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m evaluate_model_MMLU(test_model)\n",
      "Cell \u001b[0;32mIn[19], line 26\u001b[0m, in \u001b[0;36mevaluate_model_MMLU\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model_MMLU\u001b[39m(model):\n\u001b[1;32m     21\u001b[0m     benchmark \u001b[38;5;241m=\u001b[39m MMLU(\n\u001b[1;32m     22\u001b[0m         tasks\u001b[38;5;241m=\u001b[39m[MMLUTask\u001b[38;5;241m.\u001b[39mHIGH_SCHOOL_COMPUTER_SCIENCE, MMLUTask\u001b[38;5;241m.\u001b[39mASTRONOMY],\n\u001b[1;32m     23\u001b[0m         n_shots\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 26\u001b[0m     benchmark\u001b[38;5;241m.\u001b[39mevaluate(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mtask_scores\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/deepeval/benchmarks/mmlu/mmlu.py:72\u001b[0m, in \u001b[0;36mMMLU.evaluate\u001b[0;34m(self, model, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m golden \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m     70\u001b[0m         goldens, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     ):\n\u001b[0;32m---> 72\u001b[0m         prediction, score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m     73\u001b[0m             model, task, golden\n\u001b[1;32m     74\u001b[0m         )\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m score:\n\u001b[1;32m     76\u001b[0m             task_correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/deepeval/benchmarks/mmlu/mmlu.py:125\u001b[0m, in \u001b[0;36mMMLU.predict\u001b[0;34m(self, model, task, golden)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Enforced model generation\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     res: MultipleChoiceSchema \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    126\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt, schema\u001b[38;5;241m=\u001b[39mMultipleChoiceSchema\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39manswer\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[29], line 53\u001b[0m, in \u001b[0;36mGPT2.generate\u001b[0;34m(self, prompt, schema)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_dict)\n\u001b[1;32m     52\u001b[0m output \u001b[38;5;241m=\u001b[39m output_dict[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mlen\u001b[39m(prompt) :]\n\u001b[0;32m---> 53\u001b[0m json_result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(output)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Return valid JSON object according to the schema DeepEval supplied\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m schema(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson_result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "probability = [2e-9, 4e-9, 6e-9, 8e-9]\n",
    "for prob in probability:\n",
    "    while True:\n",
    "        #test_model = inject_error(gpt2, \"gpt2_targets\", prob)\n",
    "        test_model = hf_model\n",
    "        result = evaluate_model_MMLU_GPT2(test_model)\n",
    "        for i in result.index:\n",
    "            task = result.loc[i, \"Task\"]\n",
    "            score = result.loc[i, \"Score\"]\n",
    "            with open(f\"results/gpt2_{str(prob)}_{task}\", \"w\") as f:\n",
    "                f.write(f\"{str(score)}\\n\") \n",
    "        print(\"Succeeded no nan\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6d05f71-6f1e-44c3-97c6-160e87936bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   0%|                                                                                                                                                                               | 0/100 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   1%|█▋                                                                                                                                                                     | 1/100 [00:02<03:49,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   2%|███▎                                                                                                                                                                   | 2/100 [00:04<03:38,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   3%|█████                                                                                                                                                                  | 3/100 [00:06<03:39,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   4%|██████▋                                                                                                                                                                | 4/100 [00:09<03:42,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   5%|████████▎                                                                                                                                                              | 5/100 [00:11<03:40,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   6%|██████████                                                                                                                                                             | 6/100 [00:14<03:48,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   7%|███████████▋                                                                                                                                                           | 7/100 [00:16<03:46,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   8%|█████████████▎                                                                                                                                                         | 8/100 [00:18<03:37,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   9%|███████████████                                                                                                                                                        | 9/100 [00:21<03:32,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  10%|████████████████▌                                                                                                                                                     | 10/100 [00:23<03:33,  2.37s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  11%|██████████████████▎                                                                                                                                                   | 11/100 [00:26<03:33,  2.40s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  12%|███████████████████▉                                                                                                                                                  | 12/100 [00:28<03:30,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  13%|█████████████████████▌                                                                                                                                                | 13/100 [00:30<03:28,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  14%|███████████████████████▏                                                                                                                                              | 14/100 [00:33<03:28,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  15%|████████████████████████▉                                                                                                                                             | 15/100 [00:35<03:19,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  16%|██████████████████████████▌                                                                                                                                           | 16/100 [00:40<04:13,  3.02s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  17%|████████████████████████████▏                                                                                                                                         | 17/100 [00:42<03:56,  2.85s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  18%|█████████████████████████████▉                                                                                                                                        | 18/100 [00:44<03:37,  2.65s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  19%|███████████████████████████████▌                                                                                                                                      | 19/100 [00:47<03:28,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  20%|█████████████████████████████████▏                                                                                                                                    | 20/100 [00:49<03:27,  2.59s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  21%|██████████████████████████████████▊                                                                                                                                   | 21/100 [00:51<03:16,  2.49s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  22%|████████████████████████████████████▌                                                                                                                                 | 22/100 [00:54<03:10,  2.45s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  23%|██████████████████████████████████████▏                                                                                                                               | 23/100 [00:56<02:56,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  24%|███████████████████████████████████████▊                                                                                                                              | 24/100 [00:58<02:53,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  25%|█████████████████████████████████████████▌                                                                                                                            | 25/100 [01:00<02:53,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  26%|███████████████████████████████████████████▏                                                                                                                          | 26/100 [01:03<02:52,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  27%|████████████████████████████████████████████▊                                                                                                                         | 27/100 [01:05<02:56,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  28%|██████████████████████████████████████████████▍                                                                                                                       | 28/100 [01:08<02:55,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  29%|████████████████████████████████████████████████▏                                                                                                                     | 29/100 [01:13<03:40,  3.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  30%|█████████████████████████████████████████████████▊                                                                                                                    | 30/100 [01:17<03:58,  3.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  31%|███████████████████████████████████████████████████▍                                                                                                                  | 31/100 [01:20<03:59,  3.47s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  32%|█████████████████████████████████████████████████████                                                                                                                 | 32/100 [01:22<03:30,  3.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  33%|██████████████████████████████████████████████████████▊                                                                                                               | 33/100 [01:25<03:23,  3.04s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  34%|████████████████████████████████████████████████████████▍                                                                                                             | 34/100 [01:27<03:01,  2.75s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  35%|██████████████████████████████████████████████████████████                                                                                                            | 35/100 [01:29<02:42,  2.51s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  36%|███████████████████████████████████████████████████████████▊                                                                                                          | 36/100 [01:32<02:38,  2.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  37%|█████████████████████████████████████████████████████████████▍                                                                                                        | 37/100 [01:36<03:03,  2.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  38%|███████████████████████████████████████████████████████████████                                                                                                       | 38/100 [01:39<03:01,  2.93s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  39%|████████████████████████████████████████████████████████████████▋                                                                                                     | 39/100 [01:42<03:13,  3.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  40%|██████████████████████████████████████████████████████████████████▍                                                                                                   | 40/100 [01:45<02:59,  3.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  41%|████████████████████████████████████████████████████████████████████                                                                                                  | 41/100 [01:49<03:12,  3.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  42%|█████████████████████████████████████████████████████████████████████▋                                                                                                | 42/100 [01:51<02:50,  2.94s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  43%|███████████████████████████████████████████████████████████████████████▍                                                                                              | 43/100 [01:54<02:46,  2.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  44%|█████████████████████████████████████████████████████████████████████████                                                                                             | 44/100 [01:56<02:31,  2.71s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  45%|██████████████████████████████████████████████████████████████████████████▋                                                                                           | 45/100 [01:58<02:19,  2.54s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  46%|████████████████████████████████████████████████████████████████████████████▎                                                                                         | 46/100 [02:01<02:14,  2.50s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  47%|██████████████████████████████████████████████████████████████████████████████                                                                                        | 47/100 [02:03<02:08,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  48%|███████████████████████████████████████████████████████████████████████████████▋                                                                                      | 48/100 [02:05<02:02,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  49%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 49/100 [02:07<01:57,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  50%|███████████████████████████████████████████████████████████████████████████████████                                                                                   | 50/100 [02:09<01:50,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  51%|████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 51/100 [02:12<01:49,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  52%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                               | 52/100 [02:14<01:47,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  53%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 53/100 [02:16<01:43,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  54%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                            | 54/100 [02:18<01:41,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  55%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 55/100 [02:21<01:41,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  56%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 56/100 [02:23<01:39,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  57%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                                       | 57/100 [02:25<01:37,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  58%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 58/100 [02:27<01:34,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 59/100 [02:30<01:35,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 60/100 [02:33<01:38,  2.45s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 61/100 [02:34<01:28,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 62/100 [02:37<01:29,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  63%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 63/100 [02:40<01:34,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 64/100 [02:43<01:31,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 65/100 [02:45<01:24,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 66/100 [02:47<01:18,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                      | 67/100 [02:50<01:21,  2.46s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 68/100 [02:52<01:18,  2.45s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 69/100 [02:54<01:13,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 70/100 [02:57<01:13,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 71/100 [02:59<01:11,  2.46s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 72/100 [03:02<01:08,  2.46s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 73/100 [03:04<01:02,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 74/100 [03:06<01:00,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 75/100 [03:10<01:09,  2.76s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                       | 76/100 [03:12<01:03,  2.63s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 77/100 [03:18<01:20,  3.51s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 78/100 [03:20<01:11,  3.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 79/100 [03:23<01:02,  2.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 80/100 [03:29<01:21,  4.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 81/100 [03:32<01:09,  3.67s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 82/100 [03:40<01:26,  4.78s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 83/100 [03:42<01:11,  4.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 84/100 [03:45<00:59,  3.73s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 85/100 [03:48<00:52,  3.47s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 86/100 [03:50<00:44,  3.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 87/100 [03:53<00:37,  2.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 88/100 [03:55<00:32,  2.68s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 89/100 [03:57<00:28,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 90/100 [04:00<00:26,  2.67s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 91/100 [04:03<00:24,  2.74s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 92/100 [04:05<00:21,  2.63s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 93/100 [04:07<00:17,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 94/100 [04:10<00:14,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 95/100 [04:12<00:12,  2.40s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎      | 96/100 [04:15<00:10,  2.59s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 97/100 [04:17<00:07,  2.54s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 98/100 [04:20<00:05,  2.53s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 99/100 [04:22<00:02,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:25<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=high_school_computer_science): 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing astronomy:   0%|                                                                                                                                                                                                  | 0/152 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   1%|█▏                                                                                                                                                                                        | 1/152 [00:02<05:36,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   1%|██▍                                                                                                                                                                                       | 2/152 [00:04<05:35,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   2%|███▋                                                                                                                                                                                      | 3/152 [00:09<09:09,  3.69s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   3%|████▉                                                                                                                                                                                     | 4/152 [00:12<08:14,  3.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   3%|██████                                                                                                                                                                                    | 5/152 [00:14<07:05,  2.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   4%|███████▎                                                                                                                                                                                  | 6/152 [00:17<06:31,  2.68s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   5%|████████▌                                                                                                                                                                                 | 7/152 [00:19<06:15,  2.59s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   5%|█████████▊                                                                                                                                                                                | 8/152 [00:21<05:59,  2.50s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   6%|███████████                                                                                                                                                                               | 9/152 [00:23<05:35,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   7%|████████████▏                                                                                                                                                                            | 10/152 [00:26<05:42,  2.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   7%|█████████████▍                                                                                                                                                                           | 11/152 [00:36<11:08,  4.74s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   8%|██████████████▌                                                                                                                                                                          | 12/152 [00:40<10:16,  4.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   9%|███████████████▊                                                                                                                                                                         | 13/152 [00:42<08:32,  3.69s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   9%|█████████████████                                                                                                                                                                        | 14/152 [00:44<07:29,  3.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  10%|██████████████████▎                                                                                                                                                                      | 15/152 [00:46<06:31,  2.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  11%|███████████████████▍                                                                                                                                                                     | 16/152 [00:48<06:06,  2.70s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  11%|████████████████████▋                                                                                                                                                                    | 17/152 [00:50<05:42,  2.54s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  12%|█████████████████████▉                                                                                                                                                                   | 18/152 [00:53<05:37,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  12%|███████████████████████▏                                                                                                                                                                 | 19/152 [00:55<05:24,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  13%|████████████████████████▎                                                                                                                                                                | 20/152 [00:57<05:13,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  14%|█████████████████████████▌                                                                                                                                                               | 21/152 [00:59<05:01,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  14%|██████████████████████████▊                                                                                                                                                              | 22/152 [01:02<04:54,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  15%|███████████████████████████▉                                                                                                                                                             | 23/152 [01:06<06:02,  2.81s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  16%|█████████████████████████████▏                                                                                                                                                           | 24/152 [01:09<06:37,  3.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  16%|██████████████████████████████▍                                                                                                                                                          | 25/152 [01:12<06:24,  3.03s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  17%|███████████████████████████████▋                                                                                                                                                         | 26/152 [01:14<05:45,  2.74s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  18%|████████████████████████████████▊                                                                                                                                                        | 27/152 [01:17<05:36,  2.70s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  18%|██████████████████████████████████                                                                                                                                                       | 28/152 [01:20<05:32,  2.68s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  19%|███████████████████████████████████▎                                                                                                                                                     | 29/152 [01:22<05:06,  2.49s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  20%|████████████████████████████████████▌                                                                                                                                                    | 30/152 [01:24<04:56,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  20%|█████████████████████████████████████▋                                                                                                                                                   | 31/152 [01:26<04:49,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  21%|██████████████████████████████████████▉                                                                                                                                                  | 32/152 [01:28<04:31,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  22%|████████████████████████████████████████▏                                                                                                                                                | 33/152 [01:30<04:19,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  22%|█████████████████████████████████████████▍                                                                                                                                               | 34/152 [01:32<04:20,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  23%|██████████████████████████████████████████▌                                                                                                                                              | 35/152 [01:35<04:26,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  24%|███████████████████████████████████████████▊                                                                                                                                             | 36/152 [01:37<04:14,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  24%|█████████████████████████████████████████████                                                                                                                                            | 37/152 [01:39<04:11,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  25%|██████████████████████████████████████████████▎                                                                                                                                          | 38/152 [01:41<04:07,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  26%|███████████████████████████████████████████████▍                                                                                                                                         | 39/152 [01:43<04:04,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  26%|████████████████████████████████████████████████▋                                                                                                                                        | 40/152 [01:45<04:04,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  27%|█████████████████████████████████████████████████▉                                                                                                                                       | 41/152 [01:48<04:03,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  28%|███████████████████████████████████████████████████                                                                                                                                      | 42/152 [01:50<04:00,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  28%|████████████████████████████████████████████████████▎                                                                                                                                    | 43/152 [01:52<04:09,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  29%|█████████████████████████████████████████████████████▌                                                                                                                                   | 44/152 [01:55<04:10,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  30%|██████████████████████████████████████████████████████▊                                                                                                                                  | 45/152 [02:02<06:31,  3.65s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  30%|███████████████████████████████████████████████████████▉                                                                                                                                 | 46/152 [02:04<05:46,  3.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  31%|█████████████████████████████████████████████████████████▏                                                                                                                               | 47/152 [02:06<05:15,  3.00s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  32%|██████████████████████████████████████████████████████████▍                                                                                                                              | 48/152 [02:08<04:33,  2.63s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  32%|███████████████████████████████████████████████████████████▋                                                                                                                             | 49/152 [02:11<04:46,  2.78s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  33%|████████████████████████████████████████████████████████████▊                                                                                                                            | 50/152 [02:14<04:40,  2.75s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  34%|██████████████████████████████████████████████████████████████                                                                                                                           | 51/152 [02:16<04:29,  2.66s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  34%|███████████████████████████████████████████████████████████████▎                                                                                                                         | 52/152 [02:19<04:19,  2.59s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  35%|████████████████████████████████████████████████████████████████▌                                                                                                                        | 53/152 [02:21<04:00,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  36%|█████████████████████████████████████████████████████████████████▋                                                                                                                       | 54/152 [02:23<04:00,  2.45s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  36%|██████████████████████████████████████████████████████████████████▉                                                                                                                      | 55/152 [02:26<03:57,  2.45s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  37%|████████████████████████████████████████████████████████████████████▏                                                                                                                    | 56/152 [02:30<04:34,  2.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  38%|█████████████████████████████████████████████████████████████████████▍                                                                                                                   | 57/152 [02:34<05:08,  3.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  38%|██████████████████████████████████████████████████████████████████████▌                                                                                                                  | 58/152 [02:38<05:24,  3.45s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  39%|███████████████████████████████████████████████████████████████████████▊                                                                                                                 | 59/152 [02:40<04:59,  3.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  39%|█████████████████████████████████████████████████████████████████████████                                                                                                                | 60/152 [02:46<05:53,  3.84s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  40%|██████████████████████████████████████████████████████████████████████████▏                                                                                                              | 61/152 [02:50<05:54,  3.89s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  41%|███████████████████████████████████████████████████████████████████████████▍                                                                                                             | 62/152 [02:52<05:13,  3.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  41%|████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 63/152 [02:55<04:55,  3.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  42%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                           | 64/152 [02:58<04:42,  3.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  43%|███████████████████████████████████████████████████████████████████████████████                                                                                                          | 65/152 [03:00<04:08,  2.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  43%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                        | 66/152 [03:02<03:53,  2.71s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  44%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                       | 67/152 [03:05<03:38,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  45%|██████████████████████████████████████████████████████████████████████████████████▊                                                                                                      | 68/152 [03:07<03:26,  2.46s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  45%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 69/152 [03:09<03:24,  2.46s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  46%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                   | 70/152 [03:12<03:32,  2.59s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  47%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                                                  | 71/152 [03:15<03:26,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  47%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                                                 | 72/152 [03:17<03:21,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  48%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 73/152 [03:19<03:11,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  49%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                               | 74/152 [03:21<02:57,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  49%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                                             | 75/152 [03:23<02:51,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  50%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                            | 76/152 [03:29<04:08,  3.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  51%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                           | 77/152 [03:31<03:44,  2.99s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  51%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                          | 78/152 [03:34<03:26,  2.79s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  52%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                        | 79/152 [03:36<03:18,  2.72s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  53%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 80/152 [03:38<03:03,  2.54s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  53%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                      | 81/152 [03:41<02:57,  2.50s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  54%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                     | 82/152 [03:43<02:54,  2.50s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  55%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 83/152 [03:46<02:51,  2.49s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  55%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 84/152 [03:49<02:53,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                 | 85/152 [03:51<02:46,  2.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  57%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                | 86/152 [03:53<02:34,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                               | 87/152 [03:55<02:28,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 88/152 [03:57<02:30,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 89/152 [04:00<02:28,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 90/152 [04:02<02:27,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                          | 91/152 [04:05<02:25,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  61%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 92/152 [04:07<02:14,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                       | 93/152 [04:09<02:07,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                      | 94/152 [04:11<02:09,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 95/152 [04:14<02:13,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 96/152 [04:16<02:05,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 97/152 [04:18<02:02,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 98/152 [04:20<02:04,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 99/152 [04:22<01:57,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 100/152 [04:25<01:56,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 101/152 [04:27<01:54,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 102/152 [04:29<01:53,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                           | 103/152 [04:32<01:52,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 104/152 [04:34<01:46,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 105/152 [04:36<01:48,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 106/152 [04:38<01:41,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 107/152 [04:41<01:43,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 108/152 [04:43<01:39,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 109/152 [04:45<01:37,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 110/152 [04:48<01:44,  2.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 111/152 [04:50<01:39,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 112/152 [04:53<01:44,  2.60s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 113/152 [04:56<01:39,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 114/152 [04:58<01:35,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 115/152 [05:01<01:33,  2.53s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 116/152 [05:03<01:26,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 117/152 [05:06<01:29,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 118/152 [05:08<01:26,  2.54s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 119/152 [05:11<01:22,  2.51s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 120/152 [05:13<01:22,  2.58s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 121/152 [05:16<01:20,  2.61s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 122/152 [05:18<01:15,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 123/152 [05:21<01:10,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 124/152 [05:23<01:04,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 125/152 [05:25<01:04,  2.40s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 126/152 [05:27<00:56,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 127/152 [05:29<00:54,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 128/152 [05:32<00:53,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 129/152 [05:34<00:52,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 130/152 [05:36<00:51,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 131/152 [05:38<00:47,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 132/152 [05:41<00:44,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 133/152 [05:43<00:41,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 134/152 [05:45<00:41,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 135/152 [05:48<00:38,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 136/152 [05:50<00:36,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 137/152 [05:52<00:31,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 138/152 [05:54<00:30,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 139/152 [05:56<00:29,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 140/152 [05:58<00:25,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 141/152 [06:00<00:23,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 142/152 [06:03<00:22,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 143/152 [06:09<00:30,  3.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 144/152 [06:15<00:33,  4.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 145/152 [06:18<00:27,  3.91s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 146/152 [06:21<00:21,  3.56s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 147/152 [06:23<00:15,  3.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 148/152 [06:25<00:11,  2.87s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 149/152 [06:30<00:10,  3.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 150/152 [06:34<00:07,  3.69s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 151/152 [06:36<00:03,  3.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 152/152 [06:39<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=astronomy): 0.20394736842105263\n",
      "Overall MMLU Accuracy: 0.21428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model = gpt2\n",
    "result = evaluate_model_MMLU_GPT2(test_model)\n",
    "for i in result.index:\n",
    "    task = result.loc[i, \"Task\"]\n",
    "    score = result.loc[i, \"Score\"]\n",
    "    with open(f\"results/gpt2_{str(0)}_{task}\", \"w\") as f:\n",
    "        f.write(f\"{str(score)}\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeaa011f-6cf8-4027-a502-c2ca6c1da3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science:   0%|                                                                                                                                                                               | 0/100 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   1%|█▋                                                                                                                                                                     | 1/100 [00:02<04:29,  2.72s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   2%|███▎                                                                                                                                                                   | 2/100 [00:04<03:57,  2.43s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   3%|█████                                                                                                                                                                  | 3/100 [00:07<03:50,  2.37s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   4%|██████▋                                                                                                                                                                | 4/100 [00:10<04:03,  2.53s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   5%|████████▎                                                                                                                                                              | 5/100 [00:12<03:54,  2.47s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   6%|██████████                                                                                                                                                             | 6/100 [00:14<03:44,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   7%|███████████▋                                                                                                                                                           | 7/100 [00:17<03:44,  2.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   8%|█████████████▎                                                                                                                                                         | 8/100 [00:19<03:42,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:   9%|███████████████                                                                                                                                                        | 9/100 [00:21<03:36,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  10%|████████████████▌                                                                                                                                                     | 10/100 [00:24<03:32,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  11%|██████████████████▎                                                                                                                                                   | 11/100 [00:26<03:23,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  12%|███████████████████▉                                                                                                                                                  | 12/100 [00:29<03:42,  2.53s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  13%|█████████████████████▌                                                                                                                                                | 13/100 [00:31<03:39,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  14%|███████████████████████▏                                                                                                                                              | 14/100 [00:34<03:33,  2.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  15%|████████████████████████▉                                                                                                                                             | 15/100 [00:36<03:32,  2.50s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  16%|██████████████████████████▌                                                                                                                                           | 16/100 [00:39<03:25,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  17%|████████████████████████████▏                                                                                                                                         | 17/100 [00:41<03:18,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  18%|█████████████████████████████▉                                                                                                                                        | 18/100 [00:43<03:06,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  19%|███████████████████████████████▌                                                                                                                                      | 19/100 [00:45<03:09,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  20%|█████████████████████████████████▏                                                                                                                                    | 20/100 [00:48<03:04,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  21%|██████████████████████████████████▊                                                                                                                                   | 21/100 [00:50<03:03,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  22%|████████████████████████████████████▌                                                                                                                                 | 22/100 [00:52<03:01,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  23%|██████████████████████████████████████▏                                                                                                                               | 23/100 [00:54<02:53,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  24%|███████████████████████████████████████▊                                                                                                                              | 24/100 [00:57<02:52,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  25%|█████████████████████████████████████████▌                                                                                                                            | 25/100 [00:59<02:51,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  26%|███████████████████████████████████████████▏                                                                                                                          | 26/100 [01:01<02:52,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  27%|████████████████████████████████████████████▊                                                                                                                         | 27/100 [01:04<02:47,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  28%|██████████████████████████████████████████████▍                                                                                                                       | 28/100 [01:06<02:49,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  29%|████████████████████████████████████████████████▏                                                                                                                     | 29/100 [01:09<03:02,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  30%|█████████████████████████████████████████████████▊                                                                                                                    | 30/100 [01:12<02:56,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  31%|███████████████████████████████████████████████████▍                                                                                                                  | 31/100 [01:14<02:51,  2.48s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  32%|█████████████████████████████████████████████████████                                                                                                                 | 32/100 [01:16<02:44,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  33%|██████████████████████████████████████████████████████▊                                                                                                               | 33/100 [01:19<02:43,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  34%|████████████████████████████████████████████████████████▍                                                                                                             | 34/100 [01:21<02:37,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  35%|██████████████████████████████████████████████████████████                                                                                                            | 35/100 [01:23<02:32,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  36%|███████████████████████████████████████████████████████████▊                                                                                                          | 36/100 [01:26<02:29,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  37%|█████████████████████████████████████████████████████████████▍                                                                                                        | 37/100 [01:28<02:24,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  38%|███████████████████████████████████████████████████████████████                                                                                                       | 38/100 [01:30<02:27,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  39%|████████████████████████████████████████████████████████████████▋                                                                                                     | 39/100 [01:33<02:24,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  40%|██████████████████████████████████████████████████████████████████▍                                                                                                   | 40/100 [01:35<02:14,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  41%|████████████████████████████████████████████████████████████████████                                                                                                  | 41/100 [01:37<02:20,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  42%|█████████████████████████████████████████████████████████████████████▋                                                                                                | 42/100 [01:40<02:21,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  43%|███████████████████████████████████████████████████████████████████████▍                                                                                              | 43/100 [01:42<02:16,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  44%|█████████████████████████████████████████████████████████████████████████                                                                                             | 44/100 [01:45<02:15,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  45%|██████████████████████████████████████████████████████████████████████████▋                                                                                           | 45/100 [01:47<02:12,  2.40s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  46%|████████████████████████████████████████████████████████████████████████████▎                                                                                         | 46/100 [01:49<02:08,  2.37s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  47%|██████████████████████████████████████████████████████████████████████████████                                                                                        | 47/100 [01:52<02:04,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  48%|███████████████████████████████████████████████████████████████████████████████▋                                                                                      | 48/100 [01:54<01:59,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  49%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 49/100 [01:56<01:57,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  50%|███████████████████████████████████████████████████████████████████████████████████                                                                                   | 50/100 [01:58<01:55,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  51%|████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 51/100 [02:01<01:52,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  52%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                               | 52/100 [02:02<01:43,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  53%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 53/100 [02:05<01:44,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  54%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                            | 54/100 [02:07<01:43,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  55%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 55/100 [02:10<01:46,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  56%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 56/100 [02:12<01:43,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  57%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                                       | 57/100 [02:15<01:43,  2.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  58%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 58/100 [02:17<01:37,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 59/100 [02:19<01:37,  2.37s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  60%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 60/100 [02:22<01:34,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 61/100 [02:24<01:27,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 62/100 [02:26<01:25,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  63%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 63/100 [02:28<01:21,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 64/100 [02:30<01:22,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 65/100 [02:33<01:20,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 66/100 [02:35<01:16,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                      | 67/100 [02:37<01:15,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 68/100 [02:39<01:12,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 69/100 [02:42<01:11,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 70/100 [02:44<01:10,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 71/100 [02:47<01:07,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 72/100 [02:49<01:06,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 73/100 [02:51<01:01,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 74/100 [02:53<00:58,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 75/100 [02:56<00:58,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                       | 76/100 [02:59<00:59,  2.47s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 77/100 [03:02<01:00,  2.65s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 78/100 [03:04<00:55,  2.53s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 79/100 [03:06<00:51,  2.44s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 80/100 [03:09<00:48,  2.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 81/100 [03:11<00:44,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 82/100 [03:13<00:42,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 83/100 [03:16<00:41,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 84/100 [03:18<00:37,  2.37s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 85/100 [03:20<00:35,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 86/100 [03:23<00:32,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 87/100 [03:25<00:31,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 88/100 [03:28<00:28,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 89/100 [03:30<00:25,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 90/100 [03:32<00:23,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 91/100 [03:35<00:21,  2.42s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 92/100 [03:37<00:18,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 93/100 [03:39<00:16,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 94/100 [03:42<00:14,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 95/100 [03:44<00:11,  2.39s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎      | 96/100 [03:47<00:09,  2.41s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 97/100 [03:49<00:07,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 98/100 [03:51<00:04,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 99/100 [03:53<00:02,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing high_school_computer_science: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [03:55<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=high_school_computer_science): 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing astronomy:   0%|                                                                                                                                                                                                  | 0/152 [00:00<?, ?it/s]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   1%|█▏                                                                                                                                                                                        | 1/152 [00:02<06:26,  2.56s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   1%|██▍                                                                                                                                                                                       | 2/152 [00:05<06:31,  2.61s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   2%|███▋                                                                                                                                                                                      | 3/152 [00:07<06:22,  2.57s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   3%|████▉                                                                                                                                                                                     | 4/152 [00:09<05:50,  2.37s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   3%|██████                                                                                                                                                                                    | 5/152 [00:12<05:44,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   4%|███████▎                                                                                                                                                                                  | 6/152 [00:14<05:39,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   5%|████████▌                                                                                                                                                                                 | 7/152 [00:16<05:29,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   5%|█████████▊                                                                                                                                                                                | 8/152 [00:18<05:27,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   6%|███████████                                                                                                                                                                               | 9/152 [00:21<05:26,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   7%|████████████▏                                                                                                                                                                            | 10/152 [00:23<05:23,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   7%|█████████████▍                                                                                                                                                                           | 11/152 [00:25<05:31,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   8%|██████████████▌                                                                                                                                                                          | 12/152 [00:28<05:26,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   9%|███████████████▊                                                                                                                                                                         | 13/152 [00:30<05:21,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:   9%|█████████████████                                                                                                                                                                        | 14/152 [00:32<05:07,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  10%|██████████████████▎                                                                                                                                                                      | 15/152 [00:34<05:06,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  11%|███████████████████▍                                                                                                                                                                     | 16/152 [00:36<04:58,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  11%|████████████████████▋                                                                                                                                                                    | 17/152 [00:38<04:50,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  12%|█████████████████████▉                                                                                                                                                                   | 18/152 [00:41<04:56,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  12%|███████████████████████▏                                                                                                                                                                 | 19/152 [00:43<04:51,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  13%|████████████████████████▎                                                                                                                                                                | 20/152 [00:45<04:58,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  14%|█████████████████████████▌                                                                                                                                                               | 21/152 [00:47<04:47,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  14%|██████████████████████████▊                                                                                                                                                              | 22/152 [00:50<04:47,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  15%|███████████████████████████▉                                                                                                                                                             | 23/152 [00:52<04:35,  2.14s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  16%|█████████████████████████████▏                                                                                                                                                           | 24/152 [00:54<04:37,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  16%|██████████████████████████████▍                                                                                                                                                          | 25/152 [00:56<04:32,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  17%|███████████████████████████████▋                                                                                                                                                         | 26/152 [00:58<04:22,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  18%|████████████████████████████████▊                                                                                                                                                        | 27/152 [01:00<04:28,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  18%|██████████████████████████████████                                                                                                                                                       | 28/152 [01:02<04:21,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  19%|███████████████████████████████████▎                                                                                                                                                     | 29/152 [01:04<04:23,  2.14s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  20%|████████████████████████████████████▌                                                                                                                                                    | 30/152 [01:07<04:27,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  20%|█████████████████████████████████████▋                                                                                                                                                   | 31/152 [01:09<04:22,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  21%|██████████████████████████████████████▉                                                                                                                                                  | 32/152 [01:11<04:26,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  22%|████████████████████████████████████████▏                                                                                                                                                | 33/152 [01:13<04:22,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  22%|█████████████████████████████████████████▍                                                                                                                                               | 34/152 [01:16<04:24,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  23%|██████████████████████████████████████████▌                                                                                                                                              | 35/152 [01:18<04:13,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  24%|███████████████████████████████████████████▊                                                                                                                                             | 36/152 [01:20<04:01,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  24%|█████████████████████████████████████████████                                                                                                                                            | 37/152 [01:22<04:00,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  25%|██████████████████████████████████████████████▎                                                                                                                                          | 38/152 [01:24<03:57,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  26%|███████████████████████████████████████████████▍                                                                                                                                         | 39/152 [01:26<03:55,  2.08s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  26%|████████████████████████████████████████████████▋                                                                                                                                        | 40/152 [01:28<03:50,  2.06s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  27%|█████████████████████████████████████████████████▉                                                                                                                                       | 41/152 [01:30<03:59,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  28%|███████████████████████████████████████████████████                                                                                                                                      | 42/152 [01:33<04:05,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  28%|████████████████████████████████████████████████████▎                                                                                                                                    | 43/152 [01:35<04:02,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  29%|█████████████████████████████████████████████████████▌                                                                                                                                   | 44/152 [01:37<03:55,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  30%|██████████████████████████████████████████████████████▊                                                                                                                                  | 45/152 [01:39<03:55,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  30%|███████████████████████████████████████████████████████▉                                                                                                                                 | 46/152 [01:41<03:55,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  31%|█████████████████████████████████████████████████████████▏                                                                                                                               | 47/152 [01:43<03:46,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  32%|██████████████████████████████████████████████████████████▍                                                                                                                              | 48/152 [01:46<03:45,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  32%|███████████████████████████████████████████████████████████▋                                                                                                                             | 49/152 [01:48<03:40,  2.14s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  33%|████████████████████████████████████████████████████████████▊                                                                                                                            | 50/152 [01:50<03:49,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  34%|██████████████████████████████████████████████████████████████                                                                                                                           | 51/152 [01:52<03:44,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  34%|███████████████████████████████████████████████████████████████▎                                                                                                                         | 52/152 [01:55<03:44,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  35%|████████████████████████████████████████████████████████████████▌                                                                                                                        | 53/152 [01:57<03:39,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  36%|█████████████████████████████████████████████████████████████████▋                                                                                                                       | 54/152 [01:59<03:36,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  36%|██████████████████████████████████████████████████████████████████▉                                                                                                                      | 55/152 [02:01<03:30,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  37%|████████████████████████████████████████████████████████████████████▏                                                                                                                    | 56/152 [02:04<03:36,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  38%|█████████████████████████████████████████████████████████████████████▍                                                                                                                   | 57/152 [02:06<03:33,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  38%|██████████████████████████████████████████████████████████████████████▌                                                                                                                  | 58/152 [02:08<03:33,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  39%|███████████████████████████████████████████████████████████████████████▊                                                                                                                 | 59/152 [02:10<03:29,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  39%|█████████████████████████████████████████████████████████████████████████                                                                                                                | 60/152 [02:12<03:19,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  40%|██████████████████████████████████████████████████████████████████████████▏                                                                                                              | 61/152 [02:14<03:09,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  41%|███████████████████████████████████████████████████████████████████████████▍                                                                                                             | 62/152 [02:16<03:09,  2.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  41%|████████████████████████████████████████████████████████████████████████████▋                                                                                                            | 63/152 [02:19<03:16,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  42%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                           | 64/152 [02:21<03:05,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  43%|███████████████████████████████████████████████████████████████████████████████                                                                                                          | 65/152 [02:23<03:05,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  43%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                        | 66/152 [02:25<03:06,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  44%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                       | 67/152 [02:29<03:57,  2.79s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  45%|██████████████████████████████████████████████████████████████████████████████████▊                                                                                                      | 68/152 [02:32<03:46,  2.70s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  45%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 69/152 [02:34<03:29,  2.52s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  46%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                   | 70/152 [02:38<04:11,  3.07s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  47%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                                                  | 71/152 [02:41<03:52,  2.86s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  47%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                                                 | 72/152 [02:43<03:34,  2.68s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  48%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 73/152 [02:45<03:21,  2.55s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  49%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                               | 74/152 [02:47<03:14,  2.50s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  49%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                                             | 75/152 [02:49<03:01,  2.36s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  50%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                            | 76/152 [02:52<02:56,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  51%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                           | 77/152 [02:54<02:58,  2.38s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  51%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                          | 78/152 [02:56<02:51,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  52%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                        | 79/152 [02:59<02:48,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  53%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 80/152 [03:01<02:46,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  53%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                      | 81/152 [03:03<02:44,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  54%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                     | 82/152 [03:05<02:37,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  55%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 83/152 [03:08<02:34,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  55%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 84/152 [03:10<02:33,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  56%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                 | 85/152 [03:12<02:29,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  57%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                | 86/152 [03:15<02:32,  2.31s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                               | 87/152 [03:17<02:28,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 88/152 [03:19<02:29,  2.33s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 89/152 [03:22<02:24,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 90/152 [03:24<02:19,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                          | 91/152 [03:26<02:17,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  61%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 92/152 [03:28<02:11,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                       | 93/152 [03:30<02:07,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                      | 94/152 [03:32<02:08,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 95/152 [03:35<02:10,  2.28s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  63%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 96/152 [03:37<02:06,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 97/152 [03:39<02:07,  2.32s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 98/152 [03:42<02:01,  2.25s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 99/152 [03:44<01:58,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 100/152 [03:46<01:55,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 101/152 [03:48<01:55,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 102/152 [03:50<01:51,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                           | 103/152 [03:53<01:49,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                          | 104/152 [03:55<01:45,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 105/152 [03:57<01:43,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 106/152 [03:59<01:42,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 107/152 [04:02<01:42,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 108/152 [04:04<01:40,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 109/152 [04:06<01:38,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 110/152 [04:09<01:36,  2.29s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 111/152 [04:11<01:32,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 112/152 [04:13<01:31,  2.30s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 113/152 [04:15<01:23,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 114/152 [04:17<01:19,  2.09s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 115/152 [04:19<01:18,  2.12s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 116/152 [04:22<01:21,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 117/152 [04:24<01:21,  2.34s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 118/152 [04:27<01:20,  2.35s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 119/152 [04:29<01:14,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 120/152 [04:31<01:10,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 121/152 [04:33<01:08,  2.22s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 122/152 [04:35<01:07,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 123/152 [04:37<01:03,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 124/152 [04:40<01:01,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 125/152 [04:42<00:57,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 126/152 [04:44<00:55,  2.14s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 127/152 [04:46<00:52,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 128/152 [04:48<00:49,  2.05s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 129/152 [04:50<00:48,  2.11s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 130/152 [04:52<00:46,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 131/152 [04:54<00:44,  2.10s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 132/152 [04:56<00:42,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 133/152 [04:59<00:40,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 134/152 [05:01<00:38,  2.12s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 135/152 [05:03<00:36,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 136/152 [05:05<00:35,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 137/152 [05:07<00:32,  2.15s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 138/152 [05:09<00:30,  2.21s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 139/152 [05:11<00:27,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 140/152 [05:14<00:26,  2.18s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 141/152 [05:16<00:24,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 142/152 [05:18<00:21,  2.13s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 143/152 [05:20<00:19,  2.17s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 144/152 [05:22<00:17,  2.19s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 145/152 [05:25<00:15,  2.16s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 146/152 [05:27<00:13,  2.20s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 147/152 [05:29<00:11,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 148/152 [05:31<00:09,  2.26s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 149/152 [05:34<00:06,  2.27s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 150/152 [05:36<00:04,  2.24s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 151/152 [05:38<00:02,  2.23s/it]Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Processing astronomy: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 152/152 [05:40<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=astronomy): 0.15789473684210525\n",
      "Overall MMLU Accuracy: 0.17063492063492064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_model_MMLU_GPT2(gpt2_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d26ceaaf-3f90-449d-b2f6-a5546d2d7ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Task     Score\n",
       "0  high_school_computer_science  0.190000\n",
       "1                     astronomy  0.157895"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cc94a3d-ffeb-4fb4-bff8-85b67f39d4ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_school_computer_science' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result\u001b[38;5;241m.\u001b[39mloc[result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m high_school_computer_science]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'high_school_computer_science' is not defined"
     ]
    }
   ],
   "source": [
    "result.loc[result[\"Task\"] == \"high_school_computer_science\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c3ef8ab-926c-4c76-bcd0-dec163dd1261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ce79a8d-836e-4e46-8847-82cc44ff461c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2456cf02-3359-4b62-a7b3-592d59103963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded no nan\n",
      "Succeeded no nan\n"
     ]
    }
   ],
   "source": [
    "for i in result.index:\n",
    "    task = result.loc[i, \"Task\"]\n",
    "    score = result.loc[i, \"Score\"]\n",
    "    with open(f\"results/gpt2_{str(prob)}_{task}\", \"w\") as f:\n",
    "        f.write(f\"{str(score)}\\n\") \n",
    "    print(\"Succeeded no nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8431c90-3e9d-49a7-9bb6-bc9d966b7466",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ccc87-cf0f-4f79-a6f0-5716ecd690b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
