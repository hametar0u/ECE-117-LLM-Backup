{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from typing import Literal\n",
    "\n",
    "cbt_dataset_id = \"cam-cst/cbt\"\n",
    "cbt_dataset_name : Literal[\"CN\", \"NE\", \"P\", \"V\"] = \"CN\"\n",
    "\n",
    "# Load CBT-CN dataset\n",
    "dataset = load_dataset(\n",
    "    cbt_dataset_id,\n",
    "    cbt_dataset_name,\n",
    "    split=\"test\"\n",
    ")\n",
    "\n",
    "# Load Winogrande dataset\n",
    "# dataset = load_dataset(\"automated-research-group/winogrande\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentences', 'question', 'answer', 'options'],\n",
       "    num_rows: 2500\n",
       "})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentences': ['-LRB- 3 -RRB- Hollenmadchen .',\n",
       "  \"` But where is he to find the Witch-maiden ? '\",\n",
       "  'said the first bird .',\n",
       "  '` She has no settled dwelling , but is here to-day and gone to-morrow .',\n",
       "  \"He might as well try to catch the wind . '\",\n",
       "  \"The other replied , ' I do not know , certainly , where she is at present , but in three nights from now she will come to the spring to wash her face , as she does every month when the moon is full , in order that she may never grow old nor wrinkled , but may always keep the bloom of youth . '\",\n",
       "  \"` Well , ' said the first bird , ` the spring is not far from here .\",\n",
       "  \"Shall we go and see how it is she does it ? '\",\n",
       "  \"` Willingly , if you like , ' said the other .\",\n",
       "  'The youth immediately resolved to follow the birds to the spring , only two things made him uneasy : first , lest he might be asleep when the birds went , and secondly , lest he might lose sight of them , since he had not wings to carry him along so swiftly .',\n",
       "  'He was too tired to keep awake all night , yet his anxiety prevented him from sleeping soundly , and when with the earliest dawn he looked up to the tree-top , he was glad to see his feathered companions still asleep with their heads under their wings .',\n",
       "  'He ate his breakfast , and waited until the birds should start , but they did not leave the place all day .',\n",
       "  'They hopped about from one tree to another looking for food , all day long until the evening , when they went back to their old perch to sleep .',\n",
       "  \"The next day the same thing happened , but on the third morning one bird said to the other , ` To-day we must go to the spring to see the Witch-maiden wash her face . '\",\n",
       "  'They remained on the tree till noon ; then they flew away and went towards the south .',\n",
       "  \"The young man 's heart beat with anxiety lest he should lose sight of his guides , but he managed to keep the birds in view until they again perched upon a tree .\",\n",
       "  'The young man ran after them until he was quite exhausted and out of breath , and after three short rests the birds at length reached a small open space in the forest , on the edge of which they placed themselves on the top of a high tree .',\n",
       "  'When the youth had overtaken them , he saw that there was a clear spring in the middle of the space .',\n",
       "  'He sat down at the foot of the tree upon which the birds were perched , and listened attentively to what they were saying to each other .',\n",
       "  \"` The sun is not down yet , ' said the first bird ; ` we must wait yet awhile till the moon rises and the maiden comes to the spring .\"],\n",
       " 'question': \"Do you think she will see that young XXXXX sitting under the tree ? '\",\n",
       " 'answer': 'man',\n",
       " 'options': ['birds',\n",
       "  'food',\n",
       "  'maiden',\n",
       "  'man',\n",
       "  'middle',\n",
       "  'place',\n",
       "  'sight',\n",
       "  'south',\n",
       "  'wash',\n",
       "  'wings']}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Dataset Entry\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset with QA format and tokenization\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# CAPITAL A ASCII\n",
    "\n",
    "CAP_A_ASCII = 65\n",
    "\n",
    "def get_full_text(entry: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    full_text_input = (\n",
    "        \"Context: \" + \"\".join(entry[\"sentences\"]) + \"\\n\" + \"Question: \" + entry[\"question\"].replace(\"XXXXX\", \"_\") + \"\\n\"\n",
    "    )\n",
    "    full_text_input += \"\\n\".join([f\"{chr(id + CAP_A_ASCII)}. {choice}\" for id, choice in enumerate(entry[\"options\"])])\n",
    "    full_text_input += \"\\nAnswer: \"\n",
    "    return {\"full_text_input\": full_text_input}\n",
    "def tokenize_fn(entry: Dict[str, List]) -> Dict[str, List]:\n",
    "    # Get tokenized input\n",
    "    tokenized_input = tokenizer.encode(entry[\"full_text_input\"])\n",
    "    return {\"tokenized_input\": tokenized_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dcbf99065a486d88f1ba9dff7d0676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the following cell if using CBT-CN dataset\n",
    "# dataset = dataset.map(get_full_text, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the tests on the Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load in model, can be any model that supports question answering\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import randint\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "random_test_case = dataset[randint(0, len(dataset) - 1)]\n",
    "field = \"full_text_input\" # For CBT-CN dataset\n",
    "# field = \"request\" # For Winogrande dataset\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = pipe(random_test_case[\"request\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Benchmark Logits with GPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the code below this. This section needs to be changed when we find a working implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all other warnings\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"  # Suppress transformer warnings\n",
    "\n",
    "true = 0\n",
    "output_logits = torch.Tensor([])\n",
    "NUM_TESTS = 1000\n",
    "for i in tqdm(range(NUM_TESTS)):\n",
    "    inp = dataset[i][\"tokenized_input\"]\n",
    "    ans = dataset[i][\"answer\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=inp.unsqueeze(0),\n",
    "            max_new_tokens=2,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    output_logits = torch.cat((output_logits, output[0]))\n",
    "    if tokenizer.decode(output[0][-1]).strip() == ans:\n",
    "        true += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {true/NUM_TESTS: .2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
