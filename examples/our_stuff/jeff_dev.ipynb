{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# this prints out the named parameters of a model\n",
    "def print_named_params(model: nn.Module) -> None:\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy\n",
    "import timm\n",
    "torch.set_printoptions(precision = 6, sci_mode = False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../pytei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "test_model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wte.weight: torch.Size([50257, 768])\n",
      "wpe.weight: torch.Size([1024, 768])\n",
      "h.0.ln_1.weight: torch.Size([768])\n",
      "h.0.ln_1.bias: torch.Size([768])\n",
      "h.0.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.0.attn.c_attn.bias: torch.Size([2304])\n",
      "h.0.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.0.attn.c_proj.bias: torch.Size([768])\n",
      "h.0.ln_2.weight: torch.Size([768])\n",
      "h.0.ln_2.bias: torch.Size([768])\n",
      "h.0.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.0.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.0.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.0.mlp.c_proj.bias: torch.Size([768])\n",
      "h.1.ln_1.weight: torch.Size([768])\n",
      "h.1.ln_1.bias: torch.Size([768])\n",
      "h.1.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.1.attn.c_attn.bias: torch.Size([2304])\n",
      "h.1.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.1.attn.c_proj.bias: torch.Size([768])\n",
      "h.1.ln_2.weight: torch.Size([768])\n",
      "h.1.ln_2.bias: torch.Size([768])\n",
      "h.1.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.1.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.1.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.1.mlp.c_proj.bias: torch.Size([768])\n",
      "h.2.ln_1.weight: torch.Size([768])\n",
      "h.2.ln_1.bias: torch.Size([768])\n",
      "h.2.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.2.attn.c_attn.bias: torch.Size([2304])\n",
      "h.2.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.2.attn.c_proj.bias: torch.Size([768])\n",
      "h.2.ln_2.weight: torch.Size([768])\n",
      "h.2.ln_2.bias: torch.Size([768])\n",
      "h.2.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.2.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.2.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.2.mlp.c_proj.bias: torch.Size([768])\n",
      "h.3.ln_1.weight: torch.Size([768])\n",
      "h.3.ln_1.bias: torch.Size([768])\n",
      "h.3.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.3.attn.c_attn.bias: torch.Size([2304])\n",
      "h.3.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.3.attn.c_proj.bias: torch.Size([768])\n",
      "h.3.ln_2.weight: torch.Size([768])\n",
      "h.3.ln_2.bias: torch.Size([768])\n",
      "h.3.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.3.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.3.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.3.mlp.c_proj.bias: torch.Size([768])\n",
      "h.4.ln_1.weight: torch.Size([768])\n",
      "h.4.ln_1.bias: torch.Size([768])\n",
      "h.4.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.4.attn.c_attn.bias: torch.Size([2304])\n",
      "h.4.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.4.attn.c_proj.bias: torch.Size([768])\n",
      "h.4.ln_2.weight: torch.Size([768])\n",
      "h.4.ln_2.bias: torch.Size([768])\n",
      "h.4.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.4.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.4.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.4.mlp.c_proj.bias: torch.Size([768])\n",
      "h.5.ln_1.weight: torch.Size([768])\n",
      "h.5.ln_1.bias: torch.Size([768])\n",
      "h.5.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.5.attn.c_attn.bias: torch.Size([2304])\n",
      "h.5.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.5.attn.c_proj.bias: torch.Size([768])\n",
      "h.5.ln_2.weight: torch.Size([768])\n",
      "h.5.ln_2.bias: torch.Size([768])\n",
      "h.5.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.5.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.5.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.5.mlp.c_proj.bias: torch.Size([768])\n",
      "h.6.ln_1.weight: torch.Size([768])\n",
      "h.6.ln_1.bias: torch.Size([768])\n",
      "h.6.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.6.attn.c_attn.bias: torch.Size([2304])\n",
      "h.6.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.6.attn.c_proj.bias: torch.Size([768])\n",
      "h.6.ln_2.weight: torch.Size([768])\n",
      "h.6.ln_2.bias: torch.Size([768])\n",
      "h.6.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.6.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.6.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.6.mlp.c_proj.bias: torch.Size([768])\n",
      "h.7.ln_1.weight: torch.Size([768])\n",
      "h.7.ln_1.bias: torch.Size([768])\n",
      "h.7.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.7.attn.c_attn.bias: torch.Size([2304])\n",
      "h.7.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.7.attn.c_proj.bias: torch.Size([768])\n",
      "h.7.ln_2.weight: torch.Size([768])\n",
      "h.7.ln_2.bias: torch.Size([768])\n",
      "h.7.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.7.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.7.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.7.mlp.c_proj.bias: torch.Size([768])\n",
      "h.8.ln_1.weight: torch.Size([768])\n",
      "h.8.ln_1.bias: torch.Size([768])\n",
      "h.8.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.8.attn.c_attn.bias: torch.Size([2304])\n",
      "h.8.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.8.attn.c_proj.bias: torch.Size([768])\n",
      "h.8.ln_2.weight: torch.Size([768])\n",
      "h.8.ln_2.bias: torch.Size([768])\n",
      "h.8.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.8.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.8.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.8.mlp.c_proj.bias: torch.Size([768])\n",
      "h.9.ln_1.weight: torch.Size([768])\n",
      "h.9.ln_1.bias: torch.Size([768])\n",
      "h.9.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.9.attn.c_attn.bias: torch.Size([2304])\n",
      "h.9.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.9.attn.c_proj.bias: torch.Size([768])\n",
      "h.9.ln_2.weight: torch.Size([768])\n",
      "h.9.ln_2.bias: torch.Size([768])\n",
      "h.9.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.9.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.9.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.9.mlp.c_proj.bias: torch.Size([768])\n",
      "h.10.ln_1.weight: torch.Size([768])\n",
      "h.10.ln_1.bias: torch.Size([768])\n",
      "h.10.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.10.attn.c_attn.bias: torch.Size([2304])\n",
      "h.10.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.10.attn.c_proj.bias: torch.Size([768])\n",
      "h.10.ln_2.weight: torch.Size([768])\n",
      "h.10.ln_2.bias: torch.Size([768])\n",
      "h.10.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.10.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.10.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.10.mlp.c_proj.bias: torch.Size([768])\n",
      "h.11.ln_1.weight: torch.Size([768])\n",
      "h.11.ln_1.bias: torch.Size([768])\n",
      "h.11.attn.c_attn.weight: torch.Size([768, 2304])\n",
      "h.11.attn.c_attn.bias: torch.Size([2304])\n",
      "h.11.attn.c_proj.weight: torch.Size([768, 768])\n",
      "h.11.attn.c_proj.bias: torch.Size([768])\n",
      "h.11.ln_2.weight: torch.Size([768])\n",
      "h.11.ln_2.bias: torch.Size([768])\n",
      "h.11.mlp.c_fc.weight: torch.Size([768, 3072])\n",
      "h.11.mlp.c_fc.bias: torch.Size([3072])\n",
      "h.11.mlp.c_proj.weight: torch.Size([3072, 768])\n",
      "h.11.mlp.c_proj.bias: torch.Size([768])\n",
      "ln_f.weight: torch.Size([768])\n",
      "ln_f.bias: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "with open(\"targets\", \"w\") as f:\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name}: {param.shape}\")\n",
    "        f.write(f\";{name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hey how are you doing?\\n\\nI'm so glad you're here.\"]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "input_ids = tokenizer(\"Hey how are you doing?\", return_tensors= \"pt\")[\"input_ids\"]\n",
    "\n",
    "out = model.generate(input_ids, max_new_tokens=10)\n",
    "print(tokenizer.batch_decode(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer, MambaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "# test_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "test_model = MambaModel(MambaConfig()) # not sure whether this is the pretrained version or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.weight: torch.Size([50280, 768])\n",
      "layers.0.norm.weight: torch.Size([768])\n",
      "layers.0.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.0.mixer.D: torch.Size([1536])\n",
      "layers.0.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.0.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.0.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.0.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.0.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.0.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.0.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.1.norm.weight: torch.Size([768])\n",
      "layers.1.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.1.mixer.D: torch.Size([1536])\n",
      "layers.1.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.1.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.1.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.1.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.1.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.1.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.1.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.2.norm.weight: torch.Size([768])\n",
      "layers.2.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.2.mixer.D: torch.Size([1536])\n",
      "layers.2.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.2.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.2.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.2.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.2.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.2.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.2.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.3.norm.weight: torch.Size([768])\n",
      "layers.3.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.3.mixer.D: torch.Size([1536])\n",
      "layers.3.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.3.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.3.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.3.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.3.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.3.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.3.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.4.norm.weight: torch.Size([768])\n",
      "layers.4.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.4.mixer.D: torch.Size([1536])\n",
      "layers.4.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.4.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.4.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.4.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.4.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.4.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.4.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.5.norm.weight: torch.Size([768])\n",
      "layers.5.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.5.mixer.D: torch.Size([1536])\n",
      "layers.5.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.5.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.5.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.5.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.5.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.5.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.5.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.6.norm.weight: torch.Size([768])\n",
      "layers.6.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.6.mixer.D: torch.Size([1536])\n",
      "layers.6.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.6.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.6.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.6.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.6.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.6.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.6.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.7.norm.weight: torch.Size([768])\n",
      "layers.7.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.7.mixer.D: torch.Size([1536])\n",
      "layers.7.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.7.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.7.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.7.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.7.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.7.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.7.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.8.norm.weight: torch.Size([768])\n",
      "layers.8.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.8.mixer.D: torch.Size([1536])\n",
      "layers.8.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.8.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.8.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.8.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.8.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.8.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.8.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.9.norm.weight: torch.Size([768])\n",
      "layers.9.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.9.mixer.D: torch.Size([1536])\n",
      "layers.9.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.9.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.9.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.9.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.9.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.9.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.9.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.10.norm.weight: torch.Size([768])\n",
      "layers.10.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.10.mixer.D: torch.Size([1536])\n",
      "layers.10.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.10.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.10.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.10.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.10.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.10.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.10.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.11.norm.weight: torch.Size([768])\n",
      "layers.11.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.11.mixer.D: torch.Size([1536])\n",
      "layers.11.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.11.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.11.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.11.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.11.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.11.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.11.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.12.norm.weight: torch.Size([768])\n",
      "layers.12.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.12.mixer.D: torch.Size([1536])\n",
      "layers.12.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.12.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.12.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.12.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.12.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.12.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.12.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.13.norm.weight: torch.Size([768])\n",
      "layers.13.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.13.mixer.D: torch.Size([1536])\n",
      "layers.13.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.13.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.13.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.13.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.13.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.13.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.13.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.14.norm.weight: torch.Size([768])\n",
      "layers.14.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.14.mixer.D: torch.Size([1536])\n",
      "layers.14.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.14.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.14.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.14.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.14.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.14.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.14.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.15.norm.weight: torch.Size([768])\n",
      "layers.15.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.15.mixer.D: torch.Size([1536])\n",
      "layers.15.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.15.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.15.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.15.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.15.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.15.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.15.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.16.norm.weight: torch.Size([768])\n",
      "layers.16.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.16.mixer.D: torch.Size([1536])\n",
      "layers.16.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.16.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.16.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.16.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.16.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.16.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.16.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.17.norm.weight: torch.Size([768])\n",
      "layers.17.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.17.mixer.D: torch.Size([1536])\n",
      "layers.17.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.17.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.17.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.17.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.17.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.17.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.17.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.18.norm.weight: torch.Size([768])\n",
      "layers.18.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.18.mixer.D: torch.Size([1536])\n",
      "layers.18.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.18.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.18.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.18.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.18.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.18.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.18.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.19.norm.weight: torch.Size([768])\n",
      "layers.19.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.19.mixer.D: torch.Size([1536])\n",
      "layers.19.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.19.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.19.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.19.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.19.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.19.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.19.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.20.norm.weight: torch.Size([768])\n",
      "layers.20.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.20.mixer.D: torch.Size([1536])\n",
      "layers.20.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.20.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.20.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.20.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.20.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.20.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.20.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.21.norm.weight: torch.Size([768])\n",
      "layers.21.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.21.mixer.D: torch.Size([1536])\n",
      "layers.21.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.21.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.21.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.21.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.21.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.21.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.21.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.22.norm.weight: torch.Size([768])\n",
      "layers.22.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.22.mixer.D: torch.Size([1536])\n",
      "layers.22.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.22.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.22.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.22.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.22.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.22.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.22.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.23.norm.weight: torch.Size([768])\n",
      "layers.23.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.23.mixer.D: torch.Size([1536])\n",
      "layers.23.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.23.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.23.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.23.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.23.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.23.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.23.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.24.norm.weight: torch.Size([768])\n",
      "layers.24.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.24.mixer.D: torch.Size([1536])\n",
      "layers.24.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.24.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.24.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.24.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.24.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.24.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.24.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.25.norm.weight: torch.Size([768])\n",
      "layers.25.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.25.mixer.D: torch.Size([1536])\n",
      "layers.25.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.25.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.25.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.25.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.25.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.25.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.25.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.26.norm.weight: torch.Size([768])\n",
      "layers.26.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.26.mixer.D: torch.Size([1536])\n",
      "layers.26.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.26.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.26.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.26.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.26.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.26.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.26.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.27.norm.weight: torch.Size([768])\n",
      "layers.27.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.27.mixer.D: torch.Size([1536])\n",
      "layers.27.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.27.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.27.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.27.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.27.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.27.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.27.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.28.norm.weight: torch.Size([768])\n",
      "layers.28.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.28.mixer.D: torch.Size([1536])\n",
      "layers.28.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.28.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.28.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.28.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.28.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.28.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.28.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.29.norm.weight: torch.Size([768])\n",
      "layers.29.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.29.mixer.D: torch.Size([1536])\n",
      "layers.29.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.29.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.29.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.29.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.29.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.29.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.29.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.30.norm.weight: torch.Size([768])\n",
      "layers.30.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.30.mixer.D: torch.Size([1536])\n",
      "layers.30.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.30.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.30.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.30.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.30.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.30.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.30.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "layers.31.norm.weight: torch.Size([768])\n",
      "layers.31.mixer.A_log: torch.Size([1536, 16])\n",
      "layers.31.mixer.D: torch.Size([1536])\n",
      "layers.31.mixer.conv1d.weight: torch.Size([1536, 1, 4])\n",
      "layers.31.mixer.conv1d.bias: torch.Size([1536])\n",
      "layers.31.mixer.in_proj.weight: torch.Size([3072, 768])\n",
      "layers.31.mixer.x_proj.weight: torch.Size([80, 1536])\n",
      "layers.31.mixer.dt_proj.weight: torch.Size([1536, 48])\n",
      "layers.31.mixer.dt_proj.bias: torch.Size([1536])\n",
      "layers.31.mixer.out_proj.weight: torch.Size([768, 1536])\n",
      "norm_f.weight: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print_named_params(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# pattern = r\".*weight$\"\n",
    "\n",
    "# with open(\"targets_mamba\", \"w\") as f:\n",
    "#     for param_name, _ in test_model.named_parameters():\n",
    "#         if re.match(pattern, param_name):\n",
    "#             f.write(f\"{param_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out Pytei on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injector initialized.\n",
      "Error probability: 1e-07\n",
      "Data type: torch.float32\n",
      "Error model: bit\n",
      "----------Error free----------\n",
      "Outputs (error-free): MambaOutput(last_hidden_state=tensor([[[-0.405270,  0.465092, -0.649489,  ..., -0.198023, -0.018413,\n",
      "           1.771331],\n",
      "         [ 0.556003,  0.831208,  0.456582,  ...,  0.349721, -1.617129,\n",
      "           0.776332],\n",
      "         [-0.170831,  0.653865, -1.187167,  ...,  0.261039,  1.592637,\n",
      "           1.567974],\n",
      "         [ 0.836614,  1.391737, -0.590649,  ..., -0.068223, -1.537820,\n",
      "           1.564583],\n",
      "         [-0.037992,  0.238477, -1.001789,  ...,  0.189070,  1.148284,\n",
      "           1.399295],\n",
      "         [ 1.935914,  0.835130, -0.212235,  ..., -0.337746, -1.460929,\n",
      "           0.724618]]]), cache_params=<transformers.cache_utils.MambaCache object at 0x12c2b3dd0>, hidden_states=None)\n",
      "----------Error Injected----------\n",
      "The following parameters have been injected:\n",
      "dict_keys(['embeddings.weight', 'layers.0.norm.weight', 'layers.0.mixer.conv1d.weight', 'layers.0.mixer.in_proj.weight', 'layers.0.mixer.x_proj.weight', 'layers.0.mixer.dt_proj.weight', 'layers.0.mixer.out_proj.weight', 'layers.1.norm.weight', 'layers.1.mixer.conv1d.weight', 'layers.1.mixer.in_proj.weight', 'layers.1.mixer.x_proj.weight', 'layers.1.mixer.dt_proj.weight', 'layers.1.mixer.out_proj.weight', 'layers.2.norm.weight', 'layers.2.mixer.conv1d.weight', 'layers.2.mixer.in_proj.weight', 'layers.2.mixer.x_proj.weight', 'layers.2.mixer.dt_proj.weight', 'layers.2.mixer.out_proj.weight', 'layers.3.norm.weight', 'layers.3.mixer.conv1d.weight', 'layers.3.mixer.in_proj.weight', 'layers.3.mixer.x_proj.weight', 'layers.3.mixer.dt_proj.weight', 'layers.3.mixer.out_proj.weight', 'layers.4.norm.weight', 'layers.4.mixer.conv1d.weight', 'layers.4.mixer.in_proj.weight', 'layers.4.mixer.x_proj.weight', 'layers.4.mixer.dt_proj.weight', 'layers.4.mixer.out_proj.weight', 'layers.5.norm.weight', 'layers.5.mixer.conv1d.weight', 'layers.5.mixer.in_proj.weight', 'layers.5.mixer.x_proj.weight', 'layers.5.mixer.dt_proj.weight', 'layers.5.mixer.out_proj.weight', 'layers.6.norm.weight', 'layers.6.mixer.conv1d.weight', 'layers.6.mixer.in_proj.weight', 'layers.6.mixer.x_proj.weight', 'layers.6.mixer.dt_proj.weight', 'layers.6.mixer.out_proj.weight', 'layers.7.norm.weight', 'layers.7.mixer.conv1d.weight', 'layers.7.mixer.in_proj.weight', 'layers.7.mixer.x_proj.weight', 'layers.7.mixer.dt_proj.weight', 'layers.7.mixer.out_proj.weight', 'layers.8.norm.weight', 'layers.8.mixer.conv1d.weight', 'layers.8.mixer.in_proj.weight', 'layers.8.mixer.x_proj.weight', 'layers.8.mixer.dt_proj.weight', 'layers.8.mixer.out_proj.weight', 'layers.9.norm.weight', 'layers.9.mixer.conv1d.weight', 'layers.9.mixer.in_proj.weight', 'layers.9.mixer.x_proj.weight', 'layers.9.mixer.dt_proj.weight', 'layers.9.mixer.out_proj.weight', 'layers.10.norm.weight', 'layers.10.mixer.conv1d.weight', 'layers.10.mixer.in_proj.weight', 'layers.10.mixer.x_proj.weight', 'layers.10.mixer.dt_proj.weight', 'layers.10.mixer.out_proj.weight', 'layers.11.norm.weight', 'layers.11.mixer.conv1d.weight', 'layers.11.mixer.in_proj.weight', 'layers.11.mixer.x_proj.weight', 'layers.11.mixer.dt_proj.weight', 'layers.11.mixer.out_proj.weight', 'layers.12.norm.weight', 'layers.12.mixer.conv1d.weight', 'layers.12.mixer.in_proj.weight', 'layers.12.mixer.x_proj.weight', 'layers.12.mixer.dt_proj.weight', 'layers.12.mixer.out_proj.weight', 'layers.13.norm.weight', 'layers.13.mixer.conv1d.weight', 'layers.13.mixer.in_proj.weight', 'layers.13.mixer.x_proj.weight', 'layers.13.mixer.dt_proj.weight', 'layers.13.mixer.out_proj.weight', 'layers.14.norm.weight', 'layers.14.mixer.conv1d.weight', 'layers.14.mixer.in_proj.weight', 'layers.14.mixer.x_proj.weight', 'layers.14.mixer.dt_proj.weight', 'layers.14.mixer.out_proj.weight', 'layers.15.norm.weight', 'layers.15.mixer.conv1d.weight', 'layers.15.mixer.in_proj.weight', 'layers.15.mixer.x_proj.weight', 'layers.15.mixer.dt_proj.weight', 'layers.15.mixer.out_proj.weight', 'layers.16.norm.weight', 'layers.16.mixer.conv1d.weight', 'layers.16.mixer.in_proj.weight', 'layers.16.mixer.x_proj.weight', 'layers.16.mixer.dt_proj.weight', 'layers.16.mixer.out_proj.weight', 'layers.17.norm.weight', 'layers.17.mixer.conv1d.weight', 'layers.17.mixer.in_proj.weight', 'layers.17.mixer.x_proj.weight', 'layers.17.mixer.dt_proj.weight', 'layers.17.mixer.out_proj.weight', 'layers.18.norm.weight', 'layers.18.mixer.conv1d.weight', 'layers.18.mixer.in_proj.weight', 'layers.18.mixer.x_proj.weight', 'layers.18.mixer.dt_proj.weight', 'layers.18.mixer.out_proj.weight', 'layers.19.norm.weight', 'layers.19.mixer.conv1d.weight', 'layers.19.mixer.in_proj.weight', 'layers.19.mixer.x_proj.weight', 'layers.19.mixer.dt_proj.weight', 'layers.19.mixer.out_proj.weight', 'layers.20.norm.weight', 'layers.20.mixer.conv1d.weight', 'layers.20.mixer.in_proj.weight', 'layers.20.mixer.x_proj.weight', 'layers.20.mixer.dt_proj.weight', 'layers.20.mixer.out_proj.weight', 'layers.21.norm.weight', 'layers.21.mixer.conv1d.weight', 'layers.21.mixer.in_proj.weight', 'layers.21.mixer.x_proj.weight', 'layers.21.mixer.dt_proj.weight', 'layers.21.mixer.out_proj.weight', 'layers.22.norm.weight', 'layers.22.mixer.conv1d.weight', 'layers.22.mixer.in_proj.weight', 'layers.22.mixer.x_proj.weight', 'layers.22.mixer.dt_proj.weight', 'layers.22.mixer.out_proj.weight', 'layers.23.norm.weight', 'layers.23.mixer.conv1d.weight', 'layers.23.mixer.in_proj.weight', 'layers.23.mixer.x_proj.weight', 'layers.23.mixer.dt_proj.weight', 'layers.23.mixer.out_proj.weight', 'layers.24.norm.weight', 'layers.24.mixer.conv1d.weight', 'layers.24.mixer.in_proj.weight', 'layers.24.mixer.x_proj.weight', 'layers.24.mixer.dt_proj.weight', 'layers.24.mixer.out_proj.weight', 'layers.25.norm.weight', 'layers.25.mixer.conv1d.weight', 'layers.25.mixer.in_proj.weight', 'layers.25.mixer.x_proj.weight', 'layers.25.mixer.dt_proj.weight', 'layers.25.mixer.out_proj.weight', 'layers.26.norm.weight', 'layers.26.mixer.conv1d.weight', 'layers.26.mixer.in_proj.weight', 'layers.26.mixer.x_proj.weight', 'layers.26.mixer.dt_proj.weight', 'layers.26.mixer.out_proj.weight', 'layers.27.norm.weight', 'layers.27.mixer.conv1d.weight', 'layers.27.mixer.in_proj.weight', 'layers.27.mixer.x_proj.weight', 'layers.27.mixer.dt_proj.weight', 'layers.27.mixer.out_proj.weight', 'layers.28.norm.weight', 'layers.28.mixer.conv1d.weight', 'layers.28.mixer.in_proj.weight', 'layers.28.mixer.x_proj.weight', 'layers.28.mixer.dt_proj.weight', 'layers.28.mixer.out_proj.weight', 'layers.29.norm.weight', 'layers.29.mixer.conv1d.weight', 'layers.29.mixer.in_proj.weight', 'layers.29.mixer.x_proj.weight', 'layers.29.mixer.dt_proj.weight', 'layers.29.mixer.out_proj.weight', 'layers.30.norm.weight', 'layers.30.mixer.conv1d.weight', 'layers.30.mixer.in_proj.weight', 'layers.30.mixer.x_proj.weight', 'layers.30.mixer.dt_proj.weight', 'layers.30.mixer.out_proj.weight', 'layers.31.norm.weight', 'layers.31.mixer.conv1d.weight', 'layers.31.mixer.in_proj.weight', 'layers.31.mixer.x_proj.weight', 'layers.31.mixer.dt_proj.weight', 'layers.31.mixer.out_proj.weight', 'norm_f.weight'])\n",
      "Total number of errors injected: tensor(487)\n",
      "Total number of parameters: 158374656\n",
      "Time spent on error injection (second): 146.01357913017273\n",
      "Outputs (error-injected): MambaOutput(last_hidden_state=tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]]), cache_params=<transformers.cache_utils.MambaCache object at 0x12c2b0e90>, hidden_states=None)\n"
     ]
    }
   ],
   "source": [
    "from pytei import Injector\n",
    "\n",
    "model = deepcopy(test_model).to(device)\n",
    "model.eval()\n",
    "text = \"blahblahblah\"\n",
    "test_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # error_map_file = \"./targets\"\n",
    "    error_map_file = \"./targets_mamba\"\n",
    "    injector = Injector(error_map_file, p = 1e-7, device = device, verbose = True, mitigation = 'clip')\n",
    "    print('----------Error free----------')\n",
    "    error_free_out = model(**test_input) # gpt\n",
    "    # error_free_out = model.generate(test_input[\"input_ids\"]) # mamba\n",
    "    print('Outputs (error-free):', error_free_out)\n",
    "    \n",
    "    print('----------Error Injected----------')\n",
    "    injector.inject(model)\n",
    "    error_out = model(**test_input) # gpt\n",
    "    # error_out = model.generate(test_input[\"input_ids\"]) # mamba\n",
    "    print('Outputs (error-injected):', error_out)\n",
    "\n",
    "    # print('----------Error Mitigated----------')\n",
    "    # model = deepcopy(model).to(device)\n",
    "    # model.eval()\n",
    "    # injector.inject(model, use_mitigation = True)\n",
    "    # error_mitig_out = model(**test_input) # gpt\n",
    "    # error_mitig_out = model.generate(test_input[\"input_ids\"]) # mamba\n",
    "    # print('Outputs (error-mitigated):', error_mitig_out)\n",
    "\n",
    "    # injector.save_error_map('../../temp/testmap.pt', sparse = True)\n",
    "    # injector.load_error_map('../../temp/testmap.pt', sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Difference (RMSE)----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------Difference (RMSE)----------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mmean((\u001b[43merror_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43merror_free_out\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# mamba\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# rmse = torch.sqrt(torch.mean((error_out.last_hidden_state - error_free_out.last_hidden_state) ** 2)).item() # gpt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minject & error-free: \u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "print('----------Difference (RMSE)----------')\n",
    "rmse = torch.sqrt(torch.mean((error_out.last_hidden_state - error_free_out.last_hidden_state) ** 2)).item() # gpt\n",
    "print(f\"inject & error-free: \", rmse)\n",
    "rmse = torch.sqrt(torch.mean((error_mitig_out.last_hidden_state - error_free_out.last_hidden_state) ** 2)).item() # gpt\n",
    "print(f\"mitigated & error-free: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "test_model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "\n",
    "from pytei import Injector\n",
    "\n",
    "model = deepcopy(test_model).to(device)\n",
    "model.eval()\n",
    "text = \"blahblahblah\"\n",
    "test_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "\n",
    "print(\"model: \", mode.__name__)\n",
    "\n",
    "with torch.no_grad():\n",
    "    injector = Injector('./targets', p = 1e-7, device = device, verbose = True, mitigation = 'clip')\n",
    "    print('----------Error free----------')\n",
    "    error_free_out = model(**test_input)\n",
    "    print('Outputs (error-free):', error_free_out)\n",
    "    \n",
    "    print('----------Error Injected----------')\n",
    "    injector.inject(model)\n",
    "    error_out = model(**test_input)\n",
    "    print('Outputs (error-injected):', error_out)\n",
    "\n",
    "    print('----------Error Mitigated----------')\n",
    "    model = deepcopy(model).to(device)\n",
    "    model.eval()\n",
    "    injector.inject(model, use_mitigation = True)\n",
    "    error_mitig_out = model(**test_input)\n",
    "    print('Outputs (error-mitigated):', error_mitig_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTEI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
