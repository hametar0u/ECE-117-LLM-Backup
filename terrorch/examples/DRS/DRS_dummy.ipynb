{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from terrorch.terrorch import Injector\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "torch.set_printoptions(sci_mode = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Dummy Model and Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator():\n",
    "    def __init__(self, num_sample, dense_dim, sparse_dim, device) -> None:\n",
    "        super().__init__()\n",
    "        self.num_sample = num_sample\n",
    "        self.dense_dim = dense_dim\n",
    "        self.sparse_dim = sparse_dim\n",
    "        self.device = device\n",
    "    \n",
    "    def generate_dataset(self, input_sparsity): \n",
    "        self.sparse_features = nn.functional.dropout(torch.ones(size = (self.num_sample, self.sparse_dim, )), p = 1 - input_sparsity) * input_sparsity\n",
    "        self.dense_features = torch.rand(size = (self.num_sample, self.dense_dim, ))\n",
    "        self.features = torch.concat((self.sparse_features, self.dense_features), dim = -1)\n",
    "        self.features = self.features.to(self.device)\n",
    "        self.dataset = TensorDataset(self.features)\n",
    "\n",
    "    def generate_dataloader(self):\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size = 2048, shuffle = False)\n",
    "    \n",
    "    def get_data_n_loader(self):\n",
    "        return (self.dataset, self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_layer_config(mlp_layer, input_dim, hidden_dim, dense_output_dim, pred_input_dim):\n",
    "    if mlp_layer == 1:\n",
    "        dense_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dense_output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        predictor = nn.Sequential(\n",
    "            nn.Linear(pred_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    elif mlp_layer == 2:\n",
    "        dense_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dense_output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        predictor = nn.Sequential(\n",
    "            nn.Linear(pred_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "    return dense_extractor, predictor\n",
    "\n",
    "class TestDRS(nn.Module):\n",
    "    def __init__(self, sparse_dim, dense_dim, dense_extractor, predictor, embed_dim) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sparse_dim = sparse_dim\n",
    "        self.dense_dim = dense_dim\n",
    "\n",
    "        self.sparse_extractor = nn.EmbeddingBag(num_embeddings = sparse_dim, embedding_dim = embed_dim, mode = 'sum')\n",
    "        self.dense_extractor = dense_extractor\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_features = self.dense_extractor(x[..., self.sparse_dim:])\n",
    "        sparse_features = self.sparse_extractor(x[..., :self.sparse_dim].to(int)) \n",
    "        x = torch.concat((dense_features, sparse_features), dim = -1)\n",
    "        x = self.predictor(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Golden Results (error-free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {}\n",
    "dataset_generator = DatasetGenerator(num_sample, dense_dim, sparse_dim, device)\n",
    "\n",
    "\n",
    "for input_sparsity in input_sparsities:\n",
    "    dataset_generator.generate_dataset(input_sparsity)\n",
    "    dataset_generator.generate_dataloader()\n",
    "    example_data[input_sparsity] = dataset_generator.get_data_n_loader()\n",
    "\n",
    "torch.save(example_data, './example_input.pth')\n",
    "example_data = torch.load('./example_input.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dims = [64, 128, 256, 512]\n",
    "mlp_dims = [64, 128, 256, 512]\n",
    "mlp_layers = [1, 2]\n",
    "input_sparsities = [.001, .01, .1]\n",
    "dense_dim = 128\n",
    "sparse_dim = 8192\n",
    "num_sample = 10000\n",
    "\n",
    "results_golden = torch.zeros(size = (\n",
    "    len(mlp_layers),\n",
    "    len(mlp_dims),\n",
    "    len(embed_dims),\n",
    "    len(input_sparsities),\n",
    "    num_sample\n",
    "))\n",
    "example_models = {}\n",
    "\n",
    "dense_output_dim = 32\n",
    "\n",
    "for mlp_layer_i, mlp_layer in enumerate(mlp_layers):\n",
    "    for mlp_dim_i, mlp_dim in enumerate(mlp_dims):\n",
    "        for embed_dim_i, embed_dim in enumerate(embed_dims):\n",
    "            pred_input_dim = dense_output_dim + embed_dim\n",
    "            dense_extractor, predictor = mlp_layer_config(mlp_layer, dense_dim, mlp_dim, dense_output_dim, pred_input_dim)\n",
    "            test_drs = TestDRS(sparse_dim, dense_dim, dense_extractor, predictor, embed_dim)\n",
    "            for param in test_drs.parameters():\n",
    "                if len(param.shape) > 1:\n",
    "                    nn.init.kaiming_uniform_(param)\n",
    "            example_models[str(mlp_layer) + '_' + str(mlp_dim) + '_' + str(embed_dim)] = test_drs\n",
    "            test_drs = test_drs.eval().to(device)\n",
    "            for input_sparsity_i, input_sparsity in enumerate(input_sparsities):\n",
    "                _, example_loader = example_data[input_sparsity]\n",
    "                preds = []\n",
    "                for item in example_loader:\n",
    "                    pred = test_drs(*item).detach() \n",
    "                    preds.extend(pred.tolist())\n",
    "                preds = torch.tensor(preds)\n",
    "                results_golden[mlp_layer_i][mlp_dim_i][embed_dim_i][input_sparsity_i] = preds.squeeze()\n",
    "\n",
    "torch.save(example_models, './example_models.pth')    \n",
    "torch.save(results_golden, './results_golden.pth')   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Results (with error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inject to all components, MLP and embed respectively. Can play around parameters such as `mlp_dim`, `mlp_layer`, `dense_dim` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_dims = [64, 128, 256, 512]\n",
    "mlp_dims = [64, 128, 256, 512]\n",
    "mlp_layers = [1, 2]\n",
    "input_sparsities = [.001, .01, .1]\n",
    "dense_dim = 128\n",
    "sparse_dim = 8192\n",
    "num_sample = 10000\n",
    "\n",
    "bers = [1e-8, 5e-8, 1e-7, 5e-7, 1e-6]\n",
    "results_error_injected_all = torch.zeros(size = (\n",
    "    len(bers),\n",
    "    len(mlp_layers),\n",
    "    len(mlp_dims),\n",
    "    len(embed_dims),\n",
    "    len(input_sparsities),\n",
    "    num_sample\n",
    "))\n",
    "\n",
    "dense_output_dim = 32\n",
    "\n",
    "example_models = torch.load('./example_models.pth')\n",
    "\n",
    "for ber_i, ber in enumerate(bers):\n",
    "    print(ber)\n",
    "    for mlp_layer_i, mlp_layer in enumerate(mlp_layers):\n",
    "        for mlp_dim_i, mlp_dim in enumerate(mlp_dims):\n",
    "            for embed_dim_i, embed_dim in enumerate(embed_dims):\n",
    "                pred_input_dim = dense_output_dim + embed_dim\n",
    "                test_drs = example_models[str(mlp_layer) + '_' + str(mlp_dim) + '_' + str(embed_dim)]\n",
    "                test_drs = test_drs.eval().to(device)\n",
    "\n",
    "                for input_sparsity_i, input_sparsity in enumerate(input_sparsities):\n",
    "                    _, example_loader = example_data[input_sparsity]\n",
    "                    preds = []\n",
    "                    for item in example_loader:\n",
    "                        injector = Injector(ber, param_names = ['weight'], device = device, verbose = False)\n",
    "                        injector.inject(test_drs)\n",
    "                        del injector\n",
    "                        pred = test_drs(*item).detach() \n",
    "                        preds.extend(pred.tolist())\n",
    "                    preds = torch.tensor(preds)\n",
    "                    results_error_injected_all[ber_i][mlp_layer_i][mlp_dim_i][embed_dim_i][input_sparsity_i] = preds.squeeze()\n",
    "\n",
    "torch.save(results_error_injected_all, './results_error_injected_all.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dims = [64, 128, 256, 512]\n",
    "mlp_dims = [64, 128, 256, 512]\n",
    "mlp_layers = [1, 2]\n",
    "input_sparsities = [.001, .01, .1]\n",
    "dense_dim = 128\n",
    "sparse_dim = 8192\n",
    "num_sample = 10000\n",
    "\n",
    "bers = [1e-8, 5e-8, 1e-7, 5e-7, 1e-6]\n",
    "results_error_injected_mlp = torch.zeros(size = (\n",
    "    len(bers),\n",
    "    len(mlp_layers),\n",
    "    len(mlp_dims),\n",
    "    len(embed_dims),\n",
    "    len(input_sparsities),\n",
    "    num_sample\n",
    "))\n",
    "\n",
    "dense_output_dim = 32\n",
    "\n",
    "example_models = torch.load('./example_models.pth')\n",
    "\n",
    "for ber_i, ber in enumerate(bers):\n",
    "    print(ber)\n",
    "    for mlp_layer_i, mlp_layer in enumerate(mlp_layers):\n",
    "        for mlp_dim_i, mlp_dim in enumerate(mlp_dims):\n",
    "            for embed_dim_i, embed_dim in enumerate(embed_dims):\n",
    "                pred_input_dim = dense_output_dim + embed_dim\n",
    "                test_drs = example_models[str(mlp_layer) + '_' + str(mlp_dim) + '_' + str(embed_dim)]\n",
    "                test_drs = test_drs.eval().to(device)\n",
    "\n",
    "                for input_sparsity_i, input_sparsity in enumerate(input_sparsities):\n",
    "                    _, example_loader = example_data[input_sparsity]\n",
    "                    preds = []\n",
    "                    for item in example_loader:\n",
    "                        injector = Injector(ber, param_names = ['weight'], device = device, verbose = False)\n",
    "                        injector.inject(test_drs)\n",
    "                        del injector\n",
    "                        pred = test_drs(*item).detach() \n",
    "                        preds.extend(pred.tolist())\n",
    "                    preds = torch.tensor(preds)\n",
    "                    results_error_injected_mlp[ber_i][mlp_layer_i][mlp_dim_i][embed_dim_i][input_sparsity_i] = preds.squeeze()\n",
    "                    \n",
    "torch.save(results_error_injected_mlp, './results_error_injected_mlp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dims = [64, 128, 256, 512]\n",
    "mlp_dims = [64, 128, 256, 512]\n",
    "mlp_layers = [1, 2]\n",
    "input_sparsities = [.001, .01, .1]\n",
    "dense_dim = 128\n",
    "sparse_dim = 8192\n",
    "num_sample = 10000\n",
    "\n",
    "bers = [1e-8, 5e-8, 1e-7, 5e-7, 1e-6]\n",
    "results_error_injected_embed = torch.zeros(size = (\n",
    "    len(bers),\n",
    "    len(mlp_layers),\n",
    "    len(mlp_dims),\n",
    "    len(embed_dims),\n",
    "    len(input_sparsities),\n",
    "    num_sample\n",
    "))\n",
    "\n",
    "dense_output_dim = 32\n",
    "\n",
    "example_models = torch.load('./example_models.pth')\n",
    "\n",
    "for ber_i, ber in enumerate(bers):\n",
    "    print(ber)\n",
    "    for mlp_layer_i, mlp_layer in enumerate(mlp_layers):\n",
    "        for mlp_dim_i, mlp_dim in enumerate(mlp_dims):\n",
    "            for embed_dim_i, embed_dim in enumerate(embed_dims):\n",
    "                pred_input_dim = dense_output_dim + embed_dim\n",
    "                test_drs = example_models[str(mlp_layer) + '_' + str(mlp_dim) + '_' + str(embed_dim)]\n",
    "                test_drs = test_drs.eval().to(device)\n",
    "\n",
    "                for input_sparsity_i, input_sparsity in enumerate(input_sparsities):\n",
    "                    _, example_loader = example_data[input_sparsity]\n",
    "                    preds = []\n",
    "                    for item in example_loader:\n",
    "                        injector = Injector(ber, param_names = ['weight'], device = device, verbose = False)\n",
    "                        injector.inject(test_drs)\n",
    "                        del injector\n",
    "                        pred = test_drs(*item).detach() \n",
    "                        preds.extend(pred.tolist())\n",
    "                    preds = torch.tensor(preds)\n",
    "                    results_error_injected_embed[ber_i][mlp_layer_i][mlp_dim_i][embed_dim_i][input_sparsity_i] = preds.squeeze()\n",
    "\n",
    "torch.save(results_error_injected_embed, './results_error_injected_embed.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
